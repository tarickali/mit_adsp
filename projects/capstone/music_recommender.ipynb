{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyAjEw4OHmDb"
      },
      "source": [
        "# **Music Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executive Summary\n",
        "\n",
        "In this project, we were provided with a dataset containing user-song play count interactions as well as song information, with the objective of predicting the engagement level of uninteracted user-song pairs. The given dataset contained 2,000,000 user-song interactions, however after filtering less useful and indicative users and songs, we retained 117,876 interactions, and performed our analyis on ~5.89% of the total available data. From our analysis on this subset of data, we discovered that only ~6.64% of the possible user-song interactions were captured. As such, we determined that a recommendation system approach could be used to predict the engagement level between user-song pairs that are not represented in our data. By doing so, we open the opportunity to maintain and improve user engagement with the platform while also enhancing the user experience.\n",
        "\n",
        "After rigorously training various recommender system approaches and performing a thorough comparative analysis between the different models, we determined that each of the one-model approaches had subpar performance across the board for the metrics choosen to evaluate the problem. Therefore, we implemented and evaluated an ensemble approach of all these trained models and found that the collecction of these weaker models produced a slightly stronger model. Although the ensemble model still has subpar performance, we propose to utilize this approach in production as an initial step to predict the engagement levels between user-song pairs and recommend new songs to users.\n",
        "\n",
        "We advise the platform and the stakeholders to view and understand that this initial recommendation system is intended to be used as a method to gather more data and feedback from users.It is also important to take note that as user and societal tastes change with the times and events occuring in the world, any approach that is deployed will require continual modification and refinement to capture the evolving state of the general interaction between users and entertainment. Therefore, to most adequately utilize our proposed approach, we recommend that more effort be placed on collecting informative data from both users and songs as well as quantatitve feedback on the recommendations from users. The system can then be improved gradually as we gather more interaction data. Concrete steps, details, and considerations on how to implement the proposed system, system improvements, and acquire new data will be discussed below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem and solution summary\n",
        "\n",
        "The fundamental problem we are aiming to solve in this project is predicting the enjoyment and engagement level between uninteracted user-song pairs, where the proxy of user engagement, based on the data collected, is the play count (number of times a user listened to a specific song). The provided user-song interaction dataset contained only ~6.64% of all possible interactions. This insight gives rise to the opportunity utilizing a recommender system approach to suggest new and unheard songs to users. By doing so, the business can be better situated to not only maintain and capture the activity of old, current, and new users, but also improve user satisfication and engagement with the platform. However, to do this, the quality of recommendations matters since suggesting non-related or non-relevant songs, users could be pushed away from engaging and interacting with the platform.\n",
        "\n",
        "The solution we propose is not meant to be a final solution, but instead should be viewed as an important first step in solving this challenging and dynamic problem. Namely, we propose deploying an ensemble of the models trained in this project as a means to gather more data on user-song interactions as well as collect feedback from users. The main reason we suggest this approach is that based on the results of our analysis and modelling we discovered that the one-model approaches we explored were unable to reach a satisficatory level on the choosen evaluation metrics. This inability to adequately capture the complexity of the problem severely limits the business's capacity and potential to retain and expand their user base.\n",
        "\n",
        "Nevertheless, it is crucial to note that the proposed solution of combining these weaker models still does not reach satisficatory performance levels. As such, we suggest utilizing the solution as an initial step in designing a more nuanced and intricate system that can better model the relationship between users and songs. Furthermore, this base model can serve as a guide for later proposed systems and can act as a benchmark to quantify improvements.\n",
        "\n",
        "Although the current solution restricts the business's ability to compete with the market at a high-scale, this approach can serve as the driving factor for a more sustainable and desirable solution in the future. Therefore, the potential short-term losses from this project's work can set the foundation for large long-term gains.\n",
        "\n",
        "Finally, it is necessary to note that the solution currently provided has all the characteristics necessary to predict and recommend matches between user-song pairs that are present in the system but have yet to interact. However, to be appropriately used on a dynamic and ever-evolving platform, specific implementation considerations are required, which will now be discussed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendations for implementation\n",
        "\n",
        "To practically implement the proposed solution in such a way as to maximize its beneficial usage as well as enable it to serve as a stepping stone for future systems and models, a few key considerations must be taken into account. As with any decision choice, there comes with it a set of costs and benefits. As we list our implementation recommendations we will try to highlight each such tradeoff and attempt to guide the stakeholders into valuable actionable steps.\n",
        "\n",
        "The solution that we proposed comprised of deploying an ensemble of models to be used to predict the engagement between user-song pairs. The key idea behind utilizing this system in practice is then to rank for each user a set of songs that have a high predicted engagement rating and to recommend from this ordered set some number of songs. As it stands, our models can be utilized with users and songs that we have data on and exist in our database. This presents an issue, since such models are static and are not suitable to be used with an ever-changing and dynamic environment. In particular, when new users join the platform or new songs are added, we either have no or a limited amount of data on user preferences and song engagements. In technical terms, this is known as the cold-start problem. Since this problem occurs for both new users and songs, we need to specifically address each entity separately. Therefore, we will first suggest approaches for new users and then address new songs, while making note on ways to collect more informative data for each.\n",
        "\n",
        "When a new user joins and uses the platform for the first time, there is a need to recommend a finite set of songs. A naive solution would be to present the user with a set of random songs, however this has a high potential to lead to user dissatisfication due to the existence of a large amount of poor quality songs. A more intuitive and better approach would be to utilize a rank-based solution which recommends the most popular and liked songs to new users. This approach can be further broken into categories, such as new releases or most popular today, this week, this month, all-time, in your region, worldwide, etc. as well as into genres, such as pop, rap, indie, country, etc. The benefit of using this initial system is that new users are given high quality songs that are based on the engagement and enjoyment of a large community. Although each user has unique musical preferences and tastes, this mitigates the risk that comes from initially random recommendations, especially given the lack of data. Moreover, if a diverse set of genres and categories are presented, the system can quickly adapt for each user based on collected data on how they interact with the lists, and then recommend new related songs accordingly.\n",
        "\n",
        "A technical challenge with this approach is finding the ideal balance between a rank-based model and a user-personal model. However, the platform can maintain an updated list of the most popular and liked songs in each category and genre at all times and gradually filter those that are less relevant to the user while keeping present those that are. For example, if a user never listens to country music but listens to pop, then the country music is filtered away while pop songs remains. Hence, this allows for a rank-based model to be used throughout the lifetime of a user's interaction with the platform while a user-personal model is built and trained. Another key challenge with moving from a rank-based model to a user-personal model is finding a balance between exploration and exploitation. Namely, the systems needs to balance between recommending songs it believes the user would like and songs that are more experimental and risky to suggest. This issue can be practically addressed in many ways, but will suggest two here. First, the system can prompt the user to explore new songs, from which the user can either choose to accept or reject the experiment. Second, the system can inform the user of exploratory songs so users are aware that these songs are meant to improve their future listening experience.\n",
        "\n",
        "A more general and data-driven approach to combat the cold-start problem for users is to gather concrete user information during sign-up, such as nationality, age, occupation, genre preferences, etc. With this information, a content-based recommendation system can initially be used in unison with a rank-based model to recommend more personal songs to new users. However, this comes approach comes with the downside that users need to do more work before using the platform which can lead to a negative user experience and a loss of user engagement. Therefore, although this is a sound approach, we recommend considering it only if the rank-based and user-personal models are not performing at the required performance levels.\n",
        "\n",
        "When new songs are added to the system, they need to have an adequate about of exposure to a diverse set of users. This is to ensure that their quality and engagement levels can be fairly and properly accessed before increasing or decreasing their recommendation rate. The most practical way to do this is through A/B testing with different users and gather data on the different user engagement levels with the song. The system can then use this information to decide whether to increase or decrease the exposure. This adds the risk of poor quality songs being suggested to users, however one can balance the system to ensure that each user does not get suggested risky songs too often so that the negative impact is neglible to the user. On the other hand, the feedback from users can be extremely useful to indicate the rank of the song, and so the benefit outweighs the cost in this situation. Furthermore, it is important to note that in order to entice artists to continue to add songs to the platform, songs must constantly be recommended with a non-zero probability to users, ensuring that even poorly performing songs are never completely buried away.\n",
        "\n",
        "Another key component when songs are added to the system is that details about them are extremely useful. In particular, information about the artist, album, release year, genre, and duration could be used to build a content-based model that can be used to streamline the exposure of songs to relevant users. This requires slightly more work from the song provider, however this information can be used to more directly and appropriately address the cold-start problem for songs.\n",
        "\n",
        "In terms of other data to collect from user-song interactions, we suggest implementing systems to gather a more diverse set of features. A few suggestions on data features are: if a user saved the song to a playlist and how many playlists, if they liked/loved the song, if they shared the song, and if they downloaded it. The benefit of these features is that they can easily and automatically be collected with no additional associated costs. Moreover, with enough data, a stronger hybrid content and similarity/model based recommendation system can be trained and deployed that is more capable of capturing the complexity of the problem.\n",
        "\n",
        "Beyond recommendations addressing the cold-start problem and data collection, we have a few implementation notes concerning the proposed ensemble model approach. First, since the solution we propsed is composed of many individual models, the training and prediction time will increase. Depending on the resources available, this cost in time and energy may outweigh the benefit of improved performance. However, at the discretion of stakeholders and developers, the removal or addition of some small models can be dynamically adjusted. Furthermore, as the final prediction of our model is comprised of the weighted average of many models, the weighting of each model matters. To tune these weights, we recommend performing A/B testing with various weight settings to determine the best combination. Finally, since user preferences change over time, we recommend continually retraining the model on the most recent interaction data from users. Concretely, we suggest assigning weights to datapoints such that recent examples are weighted more heavily than old examples. This way, the system can quickly adapt to the gradual changes of user perferences.\n",
        "\n",
        "In conclusion, we have highlighted implementation details and improvement notes along various dimensions. Although converting the proposed solution into a practical working system requires many considerations, we have touched upon many key actionable steps that stakeholders can take into account to implement and deploy a successful system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMCaC7Q_tq1m"
      },
      "source": [
        "## **Problem Definition**\n",
        "\n",
        "### **The Context:**\n",
        "\n",
        "With advances in technology, individuals have been given more tools to become more productive with their lives and push society and humanity forward. However, these advancements have brought alongside them an increase in the number of activities an individual can select from at a given moment. As progress and success is measured in terms of productive and accomplishments in our society, one cannot enjoy the luxury to explore their artistic pursuits as freely as previous generations could. Coupled with our current ability to produce entertainment at scale more efficiently, individuals are faced with an overwhelming challenge to choose from amongst an ocean of options to best utilize their leisure time.\n",
        "\n",
        "This present a unique opportunity for the entertainment market, where platforms can compete with one another not only with the items they provide to users but also the quality of the subset of their content presented to users. By providing both good content and good recommendations that are personalized and relatable to each user, such companies are better situated to maintain and increase their user base. Hence, one key deciding factor between these platforms is their ability to determine what content a user is most likely to enjoy.\n",
        "\n",
        "For entertainment of the form of music, podcast, and audiobook, one of the best performing companies is Spotify. It is one of the fastest growing platforms in this market, with approximately [551 million users](https://newsroom.spotify.com/company-info/), due to the quality of its recommendations and its ability to capture the musical interests of its users from amongst millions of song items.\n",
        "\n",
        "By solving the problem of music recommendations, we can potentially improve both user enjoyment as well as company profits. To do this, we need to build sophisticated recommendation systems that utilizes data and information from across the platform. Although competing a company such as Spotify is currently unimaginable, this notebook is meant to serve as a first step to understand the nature of music recommendations and provide prototype recommender systems.\n",
        "\n",
        "### **The objective:**\n",
        "\n",
        "The objective of this notebook is to build recommendation systems that recommend the top n songs a user will most likely enjoy based on their song history. A part of this objective is to explore different recommendation system approaches in order to determine the most suitable and best performing approach. In particular, we will be using user-user similarity, item-item similarity, svd, coclustering, and content based approaches. In order to decide between the different models, we will be utilizing a set of evaluation metrics.\n",
        "\n",
        "### **The key questions:**\n",
        "\n",
        "Since our goal is to recommend useres songs that they are most likely to enjoy, a key question that should be answered is if the provided data and aforementioned approaches are able to adequating capture the complexity of the problem and provide good recommendations. The nature of the problem seems to require more advanced features and techniques, seeing as Spotify was able to do what other companies could not. As such, it will be informative to see if our data and approaches are capable of producing suitable evaluation metrics.\n",
        "\n",
        "### **The problem formulation**:\n",
        "\n",
        "The formal problem defintion we are trying to solve using data science is as follows. We are given two datasets `count_df`, which contains information about the `play_count` (number of times) of a user listening to a song, and `song_df` which contains information about each song. For all user-song pairs that are not present in `count_df`, i.e. songs that users have not interacted with, we would like to predict the `play_count` of that user-song pair. This is formally a recommendation problem and so we will be utilizing the `surprise` library to build recommender systems on this dataset. In order to evaluate the performance of our models, we will use the following metrics: rmse, precision@k, recall@k, and f1_score@k. The definition of the latter three are provided later in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVUiyhYTHS1t"
      },
      "source": [
        "## **Data Dictionary**\n",
        "\n",
        "The core data is the Taste Profile Subset released by the Echo Nest as part of the Million Song Dataset. There are two files in this dataset. The first file contains the details about the song id, titles, release, artist name, and the year of release. The second file contains the user id, song id, and the play count of users.\n",
        "\n",
        "song_data\n",
        "\n",
        "song_id - A unique id given to every song\n",
        "\n",
        "title - Title of the song\n",
        "\n",
        "Release - Name of the released album\n",
        "\n",
        "Artist_name - Name of the artist\n",
        "\n",
        "year - Year of release\n",
        "\n",
        "count_data\n",
        "\n",
        "user _id - A unique id given to the user\n",
        "\n",
        "song_id - A unique id given to the song\n",
        "\n",
        "play_count - Number of times the song was played\n",
        "\n",
        "## **Data Source**\n",
        "http://millionsongdataset.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRJtXkTrHxMQ"
      },
      "source": [
        "### **Importing Libraries and the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6SRzOPXI2Efn"
      },
      "outputs": [],
      "source": [
        "# Uncomment and modify the following lines of code if you are using Google Colab\n",
        "\n",
        "# from google.colab import drive\n",
        "\n",
        "# Mounting the drive\n",
        "# drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R4YvKrpzId3K"
      },
      "outputs": [],
      "source": [
        "# Used to ignore the warning given as output of the code\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Basic libraries of python for numeric and dataframe computations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import Matplotlib the Basic library for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import seaborn - Slightly advanced library for data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Import the required library to compute the cosine similarity between two vectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Import defaultdict from collections A dictionary output that does not raise a key error\n",
        "from collections import defaultdict\n",
        "\n",
        "# Import mean_squared_error : a performance metrics in sklearn\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGKX140wf-S"
      },
      "source": [
        "### **Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "si6ulhIYImck"
      },
      "outputs": [],
      "source": [
        "# Importing the datasets\n",
        "count_df = pd.read_csv('data/count_data.csv', index_col=0) # data file contains index column at position 0\n",
        "song_df = pd.read_csv('data/song_data.csv') # data file does not contain an index column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12TKB2M7XyC6"
      },
      "source": [
        "### **Understanding the data by viewing a few observations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GCLzBuYiXlPM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOAKIMP12A8C130995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBBMDR12A8C13253B</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBXHDL12A81C204C0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBYHAJ12A6701BF1D</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SODACBL12A8C13C273</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SODDNQT12A6D4F5F7E</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SODXRTY12AB0180F3B</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOFGUAY12AB017B0A8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOFRQTD12A81C233C0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOHQWYZ12A6D4FA701</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    user_id             song_id  play_count\n",
              "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1\n",
              "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2\n",
              "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0           1\n",
              "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D           1\n",
              "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODACBL12A8C13C273           1\n",
              "5  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODDNQT12A6D4F5F7E           5\n",
              "6  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODXRTY12AB0180F3B           1\n",
              "7  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFGUAY12AB017B0A8           1\n",
              "8  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOFRQTD12A81C233C0           1\n",
              "9  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOHQWYZ12A6D4FA701           1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See top 10 records of count_df data\n",
        "count_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tV1ed0ApXpu3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>title</th>\n",
              "      <th>release</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SOQMMHC12AB0180CB8</td>\n",
              "      <td>Silent Night</td>\n",
              "      <td>Monster Ballads X-Mas</td>\n",
              "      <td>Faster Pussy cat</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SOVFVAK12A8C1350D9</td>\n",
              "      <td>Tanssi vaan</td>\n",
              "      <td>Karkuteillä</td>\n",
              "      <td>Karkkiautomaatti</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SOGTUKN12AB017F4F1</td>\n",
              "      <td>No One Could Ever</td>\n",
              "      <td>Butter</td>\n",
              "      <td>Hudson Mohawke</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOBNYVR12A8C13558C</td>\n",
              "      <td>Si Vos Querés</td>\n",
              "      <td>De Culo</td>\n",
              "      <td>Yerba Brava</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SOHSBXH12A8C13B0DF</td>\n",
              "      <td>Tangle Of Aspens</td>\n",
              "      <td>Rene Ablaze Presents Winter Sessions</td>\n",
              "      <td>Der Mystic</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SOZVAPQ12A8C13B63C</td>\n",
              "      <td>Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...</td>\n",
              "      <td>Berwald: Symphonies Nos. 1/2/3/4</td>\n",
              "      <td>David Montgomery</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SOQVRHI12A6D4FB2D7</td>\n",
              "      <td>We Have Got Love</td>\n",
              "      <td>Strictly The Best Vol. 34</td>\n",
              "      <td>Sasha / Turbulence</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SOEYRFT12AB018936C</td>\n",
              "      <td>2 Da Beat Ch'yall</td>\n",
              "      <td>Da Bomb</td>\n",
              "      <td>Kris Kross</td>\n",
              "      <td>1993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SOPMIYT12A6D4F851E</td>\n",
              "      <td>Goodbye</td>\n",
              "      <td>Danny Boy</td>\n",
              "      <td>Joseph Locke</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SOJCFMH12A8C13B0C2</td>\n",
              "      <td>Mama_ mama can't you see ?</td>\n",
              "      <td>March to cadence with the US marines</td>\n",
              "      <td>The Sun Harbor's Chorus-Documentary Recordings</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              song_id                                              title  \\\n",
              "0  SOQMMHC12AB0180CB8                                       Silent Night   \n",
              "1  SOVFVAK12A8C1350D9                                        Tanssi vaan   \n",
              "2  SOGTUKN12AB017F4F1                                  No One Could Ever   \n",
              "3  SOBNYVR12A8C13558C                                      Si Vos Querés   \n",
              "4  SOHSBXH12A8C13B0DF                                   Tangle Of Aspens   \n",
              "5  SOZVAPQ12A8C13B63C  Symphony No. 1 G minor \"Sinfonie Serieuse\"/All...   \n",
              "6  SOQVRHI12A6D4FB2D7                                   We Have Got Love   \n",
              "7  SOEYRFT12AB018936C                                  2 Da Beat Ch'yall   \n",
              "8  SOPMIYT12A6D4F851E                                            Goodbye   \n",
              "9  SOJCFMH12A8C13B0C2                         Mama_ mama can't you see ?   \n",
              "\n",
              "                                release  \\\n",
              "0                 Monster Ballads X-Mas   \n",
              "1                           Karkuteillä   \n",
              "2                                Butter   \n",
              "3                               De Culo   \n",
              "4  Rene Ablaze Presents Winter Sessions   \n",
              "5      Berwald: Symphonies Nos. 1/2/3/4   \n",
              "6             Strictly The Best Vol. 34   \n",
              "7                               Da Bomb   \n",
              "8                             Danny Boy   \n",
              "9  March to cadence with the US marines   \n",
              "\n",
              "                                      artist_name  year  \n",
              "0                                Faster Pussy cat  2003  \n",
              "1                                Karkkiautomaatti  1995  \n",
              "2                                  Hudson Mohawke  2006  \n",
              "3                                     Yerba Brava  2003  \n",
              "4                                      Der Mystic     0  \n",
              "5                                David Montgomery     0  \n",
              "6                              Sasha / Turbulence     0  \n",
              "7                                      Kris Kross  1993  \n",
              "8                                    Joseph Locke     0  \n",
              "9  The Sun Harbor's Chorus-Documentary Recordings     0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See the top 10 records of song_df data\n",
        "song_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvKb5FHcXzcN"
      },
      "source": [
        "### **Let us check the data types and and missing values of each column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yyoHc_cnX19J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2000000 entries, 0 to 1999999\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Dtype \n",
            "---  ------      ----- \n",
            " 0   user_id     object\n",
            " 1   song_id     object\n",
            " 2   play_count  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 61.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# See the info of the count_df dataframe\n",
        "count_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rz3zDx_LX42y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count    Dtype \n",
            "---  ------       --------------    ----- \n",
            " 0   song_id      1000000 non-null  object\n",
            " 1   title        999983 non-null   object\n",
            " 2   release      999993 non-null   object\n",
            " 3   artist_name  1000000 non-null  object\n",
            " 4   year         1000000 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 38.1+ MB\n"
          ]
        }
      ],
      "source": [
        "# See the info of the song_df dataframe\n",
        "song_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze2TlWxpYadn"
      },
      "source": [
        "#### **Observations and Insights:** \n",
        "\n",
        "The `count_df` dataframe has 2000000 rows and three columns: `user_id`, `song_id`, and `play_count`. The dataframe contains no missing data in any of its columns. Both the `user_id` and `song_id` columns are of type `object`, which from the above overview of the dataframe looks like an internal unique identifier to differetiate between users and songs. The `play_count` column is of type `int64` which makes sense given the information held in this column.\n",
        "\n",
        "The `song_df` dataframe has 1000000 rows and five feature columns: `song_id`, `title`, `release`, `artist_name`, and `year`. The dataframe has a few missing values in its `title` (17) and `release` (7) columns. Similar to the `count_df`, the `song_id` column is of type `object`, which must correspond to the values in the `song_id` column of `count_df`. The datatypes of the other columns make sense given the information held in each.\n",
        "\n",
        "Seeing as the two dataframe as linked based on `song_id` column, we can merge the two into one dataframe on this column. This can help faciliate further data cleaning and processing, either removing missing data or filtering less valuable data items, without having to worry about missing links between the two dataframes. After merging the two, we should consider encoding the `user_id` and `song_id` columns to simplify our future data analysis and modelling steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oTeurvID2T9U"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_count</th>\n",
              "      <th>title</th>\n",
              "      <th>release</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOAKIMP12A8C130995</td>\n",
              "      <td>1</td>\n",
              "      <td>The Cove</td>\n",
              "      <td>Thicker Than Water</td>\n",
              "      <td>Jack Johnson</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBBMDR12A8C13253B</td>\n",
              "      <td>2</td>\n",
              "      <td>Entre Dos Aguas</td>\n",
              "      <td>Flamenco Para Niños</td>\n",
              "      <td>Paco De Lucia</td>\n",
              "      <td>1976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBXHDL12A81C204C0</td>\n",
              "      <td>1</td>\n",
              "      <td>Stronger</td>\n",
              "      <td>Graduation</td>\n",
              "      <td>Kanye West</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBYHAJ12A6701BF1D</td>\n",
              "      <td>1</td>\n",
              "      <td>Constellations</td>\n",
              "      <td>In Between Dreams</td>\n",
              "      <td>Jack Johnson</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SODACBL12A8C13C273</td>\n",
              "      <td>1</td>\n",
              "      <td>Learn To Fly</td>\n",
              "      <td>There Is Nothing Left To Lose</td>\n",
              "      <td>Foo Fighters</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    user_id             song_id  play_count  \\\n",
              "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1   \n",
              "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2   \n",
              "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0           1   \n",
              "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D           1   \n",
              "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SODACBL12A8C13C273           1   \n",
              "\n",
              "             title                        release    artist_name  year  \n",
              "0         The Cove             Thicker Than Water   Jack Johnson     0  \n",
              "1  Entre Dos Aguas            Flamenco Para Niños  Paco De Lucia  1976  \n",
              "2         Stronger                     Graduation     Kanye West  2007  \n",
              "3   Constellations              In Between Dreams   Jack Johnson  2005  \n",
              "4     Learn To Fly  There Is Nothing Left To Lose   Foo Fighters  1999  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Left merge the count_df and song_df data on \"song_id\" while simultaneously dropping\n",
        "# duplicates from song_df data. Name the obtained dataframe as df.\n",
        "df = pd.merge(count_df, song_df.drop_duplicates([\"song_id\"]), how=\"left\", on=\"song_id\")\n",
        "\n",
        "# Keep a raw copy of the dataframe in case revisions are needed during analysis\n",
        "df_raw = df.copy()\n",
        "\n",
        "# View the top 5 items\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWeY9ZT43XFX"
      },
      "source": [
        "**Think About It:** As the user_id and song_id are encrypted. Can they be encoded to numeric features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oxeoOVxh2T9U"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_count</th>\n",
              "      <th>title</th>\n",
              "      <th>release</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54961</td>\n",
              "      <td>153</td>\n",
              "      <td>1</td>\n",
              "      <td>The Cove</td>\n",
              "      <td>Thicker Than Water</td>\n",
              "      <td>Jack Johnson</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54961</td>\n",
              "      <td>413</td>\n",
              "      <td>2</td>\n",
              "      <td>Entre Dos Aguas</td>\n",
              "      <td>Flamenco Para Niños</td>\n",
              "      <td>Paco De Lucia</td>\n",
              "      <td>1976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54961</td>\n",
              "      <td>736</td>\n",
              "      <td>1</td>\n",
              "      <td>Stronger</td>\n",
              "      <td>Graduation</td>\n",
              "      <td>Kanye West</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54961</td>\n",
              "      <td>750</td>\n",
              "      <td>1</td>\n",
              "      <td>Constellations</td>\n",
              "      <td>In Between Dreams</td>\n",
              "      <td>Jack Johnson</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54961</td>\n",
              "      <td>1188</td>\n",
              "      <td>1</td>\n",
              "      <td>Learn To Fly</td>\n",
              "      <td>There Is Nothing Left To Lose</td>\n",
              "      <td>Foo Fighters</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  song_id  play_count            title  \\\n",
              "0    54961      153           1         The Cove   \n",
              "1    54961      413           2  Entre Dos Aguas   \n",
              "2    54961      736           1         Stronger   \n",
              "3    54961      750           1   Constellations   \n",
              "4    54961     1188           1     Learn To Fly   \n",
              "\n",
              "                         release    artist_name  year  \n",
              "0             Thicker Than Water   Jack Johnson     0  \n",
              "1            Flamenco Para Niños  Paco De Lucia  1976  \n",
              "2                     Graduation     Kanye West  2007  \n",
              "3              In Between Dreams   Jack Johnson  2005  \n",
              "4  There Is Nothing Left To Lose   Foo Fighters  1999  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply label encoding for \"user_id\" and \"song_id\"\n",
        "\n",
        "# Import the LabelEncoder object from sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instantiate a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply the fit_transform method on the encrypted columns (user_id and song_id)\n",
        "encrypted_cols = [\"user_id\", \"song_id\"]\n",
        "df[encrypted_cols] = df[encrypted_cols].apply(label_encoder.fit_transform)\n",
        "\n",
        "# View the top 5 items after transformation\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q9EFYwj35Ju"
      },
      "source": [
        "**Think About It:** As the data also contains users who have listened to very few songs and vice versa, is it required to filter the data so that it contains users who have listened to a good count of songs and vice versa?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcY5LKAQvk9J"
      },
      "source": [
        "A dataset of size 2000000 rows x 7 columns can be quite large and may require a lot of computing resources to process. This can lead to long processing times and can make it difficult to train and evaluate your model efficiently.\n",
        "In order to address this issue, it may be necessary to trim down your dataset to a more manageable size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7GGH9TW0_9uX"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the users\n",
        "users = df.user_id\n",
        "# Create a dictionary from users to their number of songs\n",
        "ratings_count = dict()\n",
        "for user in users:\n",
        "    # If we already have the user, just add 1 to their rating count\n",
        "    if user in ratings_count:\n",
        "        ratings_count[user] += 1\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[user] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-cc6mOK7_9uX"
      },
      "outputs": [],
      "source": [
        "# We want our users to have listened at least 90 songs\n",
        "RATINGS_CUTOFF = 90\n",
        "remove_users = []\n",
        "for user, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_users.append(user)\n",
        "df = df.loc[~df.user_id.isin(remove_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B5BS-Wk5_9uY"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the songs\n",
        "songs = df.song_id\n",
        "# Create a dictionary from songs to their number of users\n",
        "ratings_count = dict()\n",
        "for song in songs:\n",
        "    # If we already have the song, just add 1 to their rating count\n",
        "    if song in ratings_count:\n",
        "        ratings_count[song] += 1\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[song] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_nCtGwGO_9uY"
      },
      "outputs": [],
      "source": [
        "# We want our song to be listened by atleast 120 users to be considered\n",
        "RATINGS_CUTOFF = 120\n",
        "remove_songs = []\n",
        "for song, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_songs.append(song)\n",
        "df_final = df.loc[~df.song_id.isin(remove_songs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8qaKeoMcGpad"
      },
      "outputs": [],
      "source": [
        "# Drop records with play_count more than(>) 5\n",
        "df_final = df_final[df_final.play_count<=5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aL1JZ00o5JtQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(117876, 7)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the shape of the data\n",
        "df_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "user_id        0\n",
              "song_id        0\n",
              "play_count     0\n",
              "title          0\n",
              "release        0\n",
              "artist_name    0\n",
              "year           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if there are any missing values in the final dataframe\n",
        "df_final.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** The dataframe `df_final` after merging `count_df` and `song_df` and performing our data filtering steps has 117876 rows and 7 columns. After this preprocessing step we have reduced our dataset from 2000000 rows to 117876 rows, approximately 5.89% of our initial dataset.\n",
        "\n",
        "**Note:** after performing this data filtering step, there are no more missing values in `final_df`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZcr1Eke2T9W"
      },
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByuHmvWDeBJI"
      },
      "source": [
        "### **Let's check the total number of unique users, songs, artists in the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE_gukSJ2T9W"
      },
      "source": [
        "Total number of unique user id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n5E24_Ec2T9W"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3155"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display total number of unique user_id\n",
        "df_final[\"user_id\"].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV3BOTdJII-t"
      },
      "source": [
        "Total number of unique song id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5SlpPkIE2T9W"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "563"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display total number of unique song_id\n",
        "df_final[\"song_id\"].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGXPsCjXVpUW"
      },
      "source": [
        "Total number of unique artists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qSVUwb8h2T9X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "232"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display total number of unique artists\n",
        "df_final[\"artist_name\"].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvk-YAo-eGGW"
      },
      "source": [
        "#### **Observations and Insights:**\n",
        "\n",
        "The total number of unique `user_ids` are 3155, unique `song_ids` are 563, and unique `artists` are 232. This indicates that are 1,776,265 unique user-song combinations. Since we have 117,876 user-song interactions in our dataframe, our dataset only represents ~6.64% of all possible user-song interactions. Therefore, we are in a situation where applying a recommendation system approach will be useful.\n",
        "\n",
        "Although we will mainly be focusing directly on user-song relationships in this notebook, we note that we have 731,960 unique user-artist combinations. As there are ~2.5x more songs than artists, we know that our dataset contains multiple songs from the same artist. This information may be beneficial when recommending songs to users that have not heard all available songs of a previosuly listened to artist. However, in order to incorporate this information in our recommendation system, we will need to use a content-based approach using this textual dataset as a feature or a hybrid recommendation approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLdIfv22ISBK"
      },
      "source": [
        "### **Let's find out about the most interacted songs and interacted users**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3DyN_8atsCx"
      },
      "source": [
        "Most interacted songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qWDrvIFF2T9X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "song_id\n",
              "8582    751\n",
              "352     748\n",
              "2220    713\n",
              "1118    662\n",
              "4152    652\n",
              "5531    618\n",
              "4448    609\n",
              "6189    606\n",
              "6293    583\n",
              "1334    570\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "most_interacted_songs = df_final[\"song_id\"].value_counts()[:10]\n",
        "most_interacted_songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>song_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8582</th>\n",
              "      <td>Use Somebody</td>\n",
              "      <td>Kings Of Leon</td>\n",
              "      <td>751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>Dog Days Are Over (Radio Edit)</td>\n",
              "      <td>Florence + The Machine</td>\n",
              "      <td>748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>Sehr kosmisch</td>\n",
              "      <td>Harmonia</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1118</th>\n",
              "      <td>Clocks</td>\n",
              "      <td>Coldplay</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4152</th>\n",
              "      <td>The Scientist</td>\n",
              "      <td>Coldplay</td>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5531</th>\n",
              "      <td>Secrets</td>\n",
              "      <td>OneRepublic</td>\n",
              "      <td>618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4448</th>\n",
              "      <td>Fireflies</td>\n",
              "      <td>Charttraxx Karaoke</td>\n",
              "      <td>609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6189</th>\n",
              "      <td>Creep (Explicit)</td>\n",
              "      <td>Radiohead</td>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6293</th>\n",
              "      <td>Yellow</td>\n",
              "      <td>Coldplay</td>\n",
              "      <td>583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>Hey_ Soul Sister</td>\n",
              "      <td>Train</td>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  title             artist_name  count\n",
              "song_id                                                               \n",
              "8582                       Use Somebody           Kings Of Leon    751\n",
              "352      Dog Days Are Over (Radio Edit)  Florence + The Machine    748\n",
              "2220                      Sehr kosmisch                Harmonia    713\n",
              "1118                             Clocks                Coldplay    662\n",
              "4152                      The Scientist                Coldplay    652\n",
              "5531                            Secrets             OneRepublic    618\n",
              "4448                          Fireflies      Charttraxx Karaoke    609\n",
              "6189                   Creep (Explicit)               Radiohead    606\n",
              "6293                             Yellow                Coldplay    583\n",
              "1334                   Hey_ Soul Sister                   Train    570"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the title and artist name for the most interacted songs\n",
        "most_interacted_song_info = df_final[df_final[\"song_id\"].isin(most_interacted_songs.index)][[\"song_id\", \"title\", \"artist_name\"]].set_index(\"song_id\").drop_duplicates()\n",
        "most_interacted_song_info[\"count\"] = most_interacted_songs\n",
        "most_interacted_song_info = most_interacted_song_info.sort_values(by=\"count\", ascending=False)\n",
        "most_interacted_song_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnoXCc9zIV45"
      },
      "source": [
        "Most interacted users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "971EiBdf2T9X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "user_id\n",
              "61472    243\n",
              "15733    227\n",
              "37049    202\n",
              "9570     184\n",
              "23337    177\n",
              "10763    176\n",
              "26616    175\n",
              "9097     175\n",
              "43041    174\n",
              "65994    171\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final[\"user_id\"].value_counts()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPZRc1e-eyyO"
      },
      "source": [
        "#### **Observations and Insights:**\n",
        "\n",
        "The most interacted song has `song_id=8582` corresponding to the song \"Use Somebody\" by \"Kings of Leon\" with 751 interactions. Since there are 3155 unique users in our dataset, there are 2404 users that have yet to interact with this song. This means that all songs have >= 2404 users that have still not interacted with them. By using a recommendation system, we can potentially increase the exposure of this song as well as the other less-interacted-with songs in our dataset. Note that the list of the top ten most interacted songs along with their counts are presented above in `most_interacted_song_info`.\n",
        "\n",
        "The most interacted user has `user_id=243` with 243 interactions. Since there are 563 unique songs in our dataset, there are 320 songs that this user has not interacted with yet. This means that all users have >= 320 songs that they still have not interacted with. This allows for the usage of a recommendation system to suggest unheard songs to users that they may enjoy. Note that the list of the top ten most interacted users are presented above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joFF5zndX1Dk"
      },
      "source": [
        "Songs played in a year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bQp2iVMC2T9Y"
      },
      "outputs": [],
      "source": [
        "# Find out the number of songs played in a year\n",
        "  # Hint: Use groupby function on the 'year' column\n",
        "songs_played_in_year = df_final.groupby(by=\"year\")[\"play_count\"].sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "year\n",
              "0       37358\n",
              "2009    28328\n",
              "2008    23173\n",
              "2007    21750\n",
              "2003    12787\n",
              "Name: play_count, dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show top 5 years\n",
        "songs_played_in_year.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "year\n",
              "1971    240\n",
              "1981    238\n",
              "1970    202\n",
              "1978    179\n",
              "1983    171\n",
              "Name: play_count, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show bottom 5 years\n",
        "songs_played_in_year.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count       37.000000\n",
              "mean      5416.108108\n",
              "std       8797.892190\n",
              "min        171.000000\n",
              "25%        437.000000\n",
              "50%       1081.000000\n",
              "75%       7200.000000\n",
              "max      37358.000000\n",
              "Name: play_count, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show description of the songs_played_in_year Series\n",
        "songs_played_in_year.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        0\n",
              "1     1969\n",
              "2     1970\n",
              "3     1971\n",
              "4     1973\n",
              "5     1974\n",
              "6     1975\n",
              "7     1976\n",
              "8     1978\n",
              "9     1979\n",
              "10    1980\n",
              "11    1981\n",
              "12    1982\n",
              "13    1983\n",
              "14    1986\n",
              "15    1987\n",
              "16    1988\n",
              "17    1990\n",
              "18    1991\n",
              "19    1992\n",
              "20    1993\n",
              "21    1994\n",
              "22    1995\n",
              "23    1996\n",
              "24    1997\n",
              "25    1999\n",
              "26    2000\n",
              "27    2001\n",
              "28    2002\n",
              "29    2003\n",
              "30    2004\n",
              "31    2005\n",
              "32    2006\n",
              "33    2007\n",
              "34    2008\n",
              "35    2009\n",
              "36    2010\n",
              "Name: year, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The years songs were released in the dataframe\n",
        "years_present = pd.Series(songs_played_in_year.index).sort_values().reset_index(drop=True)\n",
        "years_present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1972, 1977, 1984, 1985, 1989, 1998}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute years not present in the dataset\n",
        "years_present = years_present.drop(0)\n",
        "years_not_present = set(range(years_present.min(), years_present.max())).difference(set(years_present))\n",
        "years_not_present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bZCkOiAB2T9Y"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a barplot plot with y label as \"number of titles played\" and x -axis year\n",
        "\n",
        "# Set the figure size\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "\n",
        "# Create the barplot\n",
        "sns.barplot(songs_played_in_year, ax=ax)\n",
        "\n",
        "# Set the x and y label of the plot\n",
        "ax.set(xlabel=\"Year\", ylabel=\"Number of Titles Played\")\n",
        "\n",
        "#  Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUcXc7ZYfaGl"
      },
      "source": [
        "#### **Observations and Insights:**\n",
        "\n",
        "The above barplot depicts the total play count of songs according to their release years. From the exploration and description of the `Series` that produced the barplot, we see that there are 37 years represented in our dataset, ranging from 1969 to 2010 including the strange year 0 value. The total play counts ranges from 171 in year 1983 to 37358 in year 0.\n",
        "\n",
        "It is important to note that the existence of year 0 in the dataset could be the result of several factors, however it is most likely caused by missing year data that was imputed to have value 0. We can not be sure of this until we are able to contact the creator/publisher of the dataset concerning this issue.\n",
        "\n",
        "If the cause of having year 0 in our dataset is a result of imputed missing data, then this means that we are missing 37358 out of 117876, ~31.69%, of year data. This should not present a problem for the similarity-based, model-based, and content-based recommendation approachs that we will explore in this notebook. However, if in the future we want to use the year a song was released as a feature to recommend new songs to users, then we need to take care of the fact that year 0 is an imputed value. Also, note that year 0 having the highest play count in our dataframe makes sense based on the above explanation.\n",
        "\n",
        "Finally, we noticed that a few years are not present in our dataset between the range of 1969 to 2010. Namely, 1972, 1977, 1984, 1985, 1989, 1998. Perhaps few songs were released during these year or the songs from these years are less popular and were filtered out during our preprocessing stage. It may be interesting to look into the cause of these missing years in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtAjyDMioHCp"
      },
      "source": [
        "**Think About It:** What other insights can be drawn using exploratory data analysis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWO4C8KsK_5e"
      },
      "source": [
        "Now that we have explored the data, let's apply different algorithms to build recommendation systems.\n",
        "\n",
        "**Note:** Use the shorter version of the data, i.e., the data after the cutoffs as used in Milestone 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VThYg7voGIz"
      },
      "source": [
        "## Building various models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Disclaimer:** Due to the random nature of model training, some results have changed from re-running this notebook. The comparisons and conclusions presented are based on the results submitted from the initial Milestone notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ituk9wA4Idib"
      },
      "source": [
        "### **Popularity-Based Recommendation Systems**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "462hsbxaI1ED"
      },
      "source": [
        "Let's take the count and sum of play counts of the songs and build the popularity recommendation systems based on the sum of play counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UXhBZlDE-jEu"
      },
      "outputs": [],
      "source": [
        "# Group dataframe by song_id\n",
        "song_gb = df_final.groupby(by=[\"song_id\"])\n",
        "\n",
        "# Calculating average play_count\n",
        "average_count = song_gb[\"play_count\"].mean()\n",
        "\n",
        "# Calculating the frequency a song is played\n",
        "play_frequency = song_gb[\"play_count\"].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "v2XYdXvWdyys"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_count</th>\n",
              "      <th>play_frequency</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>song_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.622642</td>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.492424</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1.729216</td>\n",
              "      <td>728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>1.728070</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>1.452174</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         average_count  play_frequency\n",
              "song_id                               \n",
              "21            1.622642             430\n",
              "22            1.492424             197\n",
              "52            1.729216             728\n",
              "62            1.728070             197\n",
              "93            1.452174             167"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making a dataframe with the average_count and play_freq\n",
        "final_play = pd.DataFrame({\"average_count\": average_count, \"play_frequency\": play_frequency})\n",
        "\n",
        "# Let us see the first five records of the final_play dataset\n",
        "final_play.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_count</th>\n",
              "      <th>play_frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>563.000000</td>\n",
              "      <td>563.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.652936</td>\n",
              "      <td>355.943162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.217654</td>\n",
              "      <td>236.086819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.238710</td>\n",
              "      <td>146.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.492805</td>\n",
              "      <td>206.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.626761</td>\n",
              "      <td>256.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.765858</td>\n",
              "      <td>400.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.373832</td>\n",
              "      <td>1634.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       average_count  play_frequency\n",
              "count     563.000000      563.000000\n",
              "mean        1.652936      355.943162\n",
              "std         0.217654      236.086819\n",
              "min         1.238710      146.000000\n",
              "25%         1.492805      206.500000\n",
              "50%         1.626761      256.000000\n",
              "75%         1.765858      400.500000\n",
              "max         3.373832     1634.000000"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show description of the final_play dataset\n",
        "final_play.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnCT-A7RK_5g"
      },
      "source": [
        "Now, let's create a function to find the top n songs for a recommendation based on the average play count of song. We can also add a threshold for a minimum number of playcounts for a song to be considered for recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QiT9FV3GNCrb"
      },
      "outputs": [],
      "source": [
        "# Build the function to find top n songs\n",
        "def top_n(data: pd.DataFrame, n: int, col_x=\"average_count\", col_y=\"play_frequency\", threshold: int = 0) -> pd.DataFrame:\n",
        "    \"\"\"Returns the top n products in a dataframe along col_x\n",
        "    conditioned if the value of col_y > threshold.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "    n : int\n",
        "    col_x : str = \"average_count\"\n",
        "        The name of the column to compute the top n items on.\n",
        "    col_y : str = \"play_frequency\"\n",
        "        The name of the column to check against threshold.\n",
        "    threshold : int = 10\n",
        "        The value used to filter against col_y values.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Finding data with values of col_y > threshold\n",
        "    threshold_data = data[data[col_y] > threshold]\n",
        "    \n",
        "    # Sorting values with respect to col_x\n",
        "    threshold_data = threshold_data.sort_values(by=col_x, ascending=False)\n",
        "\n",
        "    # Return the top n values\n",
        "    return threshold_data.head(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GpZt_BeXgz4F"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>average_count</th>\n",
              "      <th>play_frequency</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>song_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7224</th>\n",
              "      <td>Victoria (LP Version)</td>\n",
              "      <td>Old 97's</td>\n",
              "      <td>3.373832</td>\n",
              "      <td>361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8324</th>\n",
              "      <td>The Big Gundown</td>\n",
              "      <td>The Prodigy</td>\n",
              "      <td>2.625000</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6450</th>\n",
              "      <td>Brave The Elements</td>\n",
              "      <td>Colossal</td>\n",
              "      <td>2.578431</td>\n",
              "      <td>263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9942</th>\n",
              "      <td>Greece 2000</td>\n",
              "      <td>Three Drives</td>\n",
              "      <td>2.486667</td>\n",
              "      <td>373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5531</th>\n",
              "      <td>Secrets</td>\n",
              "      <td>OneRepublic</td>\n",
              "      <td>2.309061</td>\n",
              "      <td>1427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5653</th>\n",
              "      <td>Transparency</td>\n",
              "      <td>White Denim</td>\n",
              "      <td>2.296296</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8483</th>\n",
              "      <td>Video Killed The Radio Star</td>\n",
              "      <td>The Buggles</td>\n",
              "      <td>2.235772</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>Sehr kosmisch</td>\n",
              "      <td>Harmonia</td>\n",
              "      <td>2.220196</td>\n",
              "      <td>1583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>Luvstruck</td>\n",
              "      <td>Southside Spinners</td>\n",
              "      <td>2.218543</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614</th>\n",
              "      <td>You're The One</td>\n",
              "      <td>Dwight Yoakam</td>\n",
              "      <td>2.217158</td>\n",
              "      <td>827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               title         artist_name  average_count  \\\n",
              "song_id                                                                   \n",
              "7224           Victoria (LP Version)            Old 97's       3.373832   \n",
              "8324                 The Big Gundown         The Prodigy       2.625000   \n",
              "6450              Brave The Elements            Colossal       2.578431   \n",
              "9942                     Greece 2000        Three Drives       2.486667   \n",
              "5531                         Secrets         OneRepublic       2.309061   \n",
              "5653                    Transparency         White Denim       2.296296   \n",
              "8483     Video Killed The Radio Star         The Buggles       2.235772   \n",
              "2220                   Sehr kosmisch            Harmonia       2.220196   \n",
              "657                        Luvstruck  Southside Spinners       2.218543   \n",
              "614                   You're The One       Dwight Yoakam       2.217158   \n",
              "\n",
              "         play_frequency  \n",
              "song_id                  \n",
              "7224                361  \n",
              "8324                252  \n",
              "6450                263  \n",
              "9942                373  \n",
              "5531               1427  \n",
              "5653                248  \n",
              "8483                275  \n",
              "2220               1583  \n",
              "657                 335  \n",
              "614                 827  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Recommend top 10 songs using the function defined above\n",
        "\n",
        "# Get the top 10 song based on average play_counts thresholded by having play_frequency > 200\n",
        "top_10_songs_counts = top_n(data=final_play, n=10, col_x=\"average_count\", col_y=\"play_frequency\", threshold=200)\n",
        "\n",
        "# Get the title and artist_name information corresponding to the top 10 songs\n",
        "top_10_songs_info = df_final[df_final[\"song_id\"].isin(top_10_songs_counts.index)][[\"song_id\", \"title\", \"artist_name\"]].set_index(\"song_id\").drop_duplicates()\n",
        "\n",
        "# Join the top 10 song counts to the information table and sort based on average_count\n",
        "top_10_songs = top_10_songs_info.join(top_10_songs_counts).sort_values(by=\"average_count\", ascending=False)\n",
        "top_10_songs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** The above dataframe shows the top 10 most popular songs based on `average_count` in our dataframe after filtering away all songs with `play_frequency` < 200, including the song `title` and `artist_name`. The most popular in terms of `average_count` has `song_id=7224` and corresponds to \"Victoria (LP Version)\" by \"Old 97's\" with an average play count of ~3.37.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>average_count</th>\n",
              "      <th>play_frequency</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>song_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5531</th>\n",
              "      <td>Secrets</td>\n",
              "      <td>OneRepublic</td>\n",
              "      <td>2.309061</td>\n",
              "      <td>1427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>Sehr kosmisch</td>\n",
              "      <td>Harmonia</td>\n",
              "      <td>2.220196</td>\n",
              "      <td>1583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 title  artist_name  average_count  play_frequency\n",
              "song_id                                                           \n",
              "5531           Secrets  OneRepublic       2.309061            1427\n",
              "2220     Sehr kosmisch     Harmonia       2.220196            1583"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The top 10 most popular songs that are also in the top 10 most interacted songs.\n",
        "top_10_songs.loc[list(set(top_10_songs.index) & set(most_interacted_songs.index))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** The above dataframe shows that amongst the top 10 songs based on average play counts, two of them, namely \"Secrets\" by \"OneRepublic\" and \"Sehr kosmisch\" by \"Harmonia\" are also two of the most interacted songs in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf13HrPPJeWT"
      },
      "source": [
        "### **User User Similarity-Based Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROcEpduohdua"
      },
      "source": [
        "To build the user-user-similarity-based and subsequent models we will use the \"surprise\" library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aKLrKn8IfGjk"
      },
      "outputs": [],
      "source": [
        "# Install the surprise package using pip. Uncomment and run the below code to do the same\n",
        "\n",
        "# !pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UJ1wEylUpexj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "# To add type-checking and code completion in functions\n",
        "from surprise.prediction_algorithms import AlgoBase\n",
        "\n",
        "# To compute the accuracy of models\n",
        "from surprise import accuracy\n",
        "\n",
        "# This class is used to parse a file containing play_counts, data should be in structure - user; item; play_count\n",
        "from surprise.reader import Reader\n",
        "\n",
        "# Class for loading datasets\n",
        "from surprise.dataset import Dataset\n",
        "\n",
        "# For tuning model hyperparameters\n",
        "from surprise.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# For splitting the data in train and test dataset\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# For implementing similarity-based recommendation system\n",
        "from surprise.prediction_algorithms import KNNBasic\n",
        "\n",
        "# For implementing matrix factorization based recommendation system\n",
        "from surprise.prediction_algorithms import SVD\n",
        "\n",
        "# For implementing KFold cross-validation\n",
        "from surprise.model_selection import KFold\n",
        "\n",
        "# For implementing clustering-based recommendation system\n",
        "from surprise.prediction_algorithms import CoClustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBW4BUhWTsnm"
      },
      "source": [
        "### Some useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhFa_4aHHchr"
      },
      "source": [
        "Below is the function to calculate precision@k and recall@k, RMSE, and F1_Score@k to evaluate the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOvOgjGWrMVV"
      },
      "source": [
        "**Think About It:** Which metric should be used for this problem to compare different models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Terminology Note:**\n",
        "\n",
        "Before we build recommendation systems for this problem, we will introduce some terminology that we will use throughout the notebook.\n",
        "\n",
        "**Relevant item:** An item whose **actual rating is higher than a threshold value** is relevant, otherwise it is not relevant.\n",
        "\n",
        "**Recommended item:** An item whose **predicted rating is higher than a threshold value** is recommended, otherwise it is not recommended\n",
        "\n",
        "**False Negative (FN):** The frequency of **relevant** item that are **not** **recommended**\n",
        "\n",
        "**False Positive (FP):** The frequency of **recommended** items that are not **relevant**.\n",
        "\n",
        "**Recall:** The fraction of **relevant** items that are recommended. A model with a high recall has a low false negative rate, which indicates the model has a low rate of not recommending a relevant product. In turn, such a model reduces the opportunity loss of the company.\n",
        "\n",
        "**Precision:** The fraction of **recommended** items are that relevant. A model with a high precision has a low false positive rate, which indicates the model has a low rate of recommending a non-relevant product. In turn, such a model increases the enjoyment of the user.\n",
        "\n",
        "**Recall@k:** The fraction of **relevant** items that are recommended in `top k` predictions.\n",
        "\n",
        "**Precision@k:** The fraction of **recommended** items are that relevant in `top k` predictions.\n",
        "\n",
        "**F1-score@k:** The harmonic mean of **precision@k** and **recall@k**.\n",
        "\n",
        "**NOTE:** All three metrics, **recall@k**, **precision@k** and **f1_score@k** are important for this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Rxn-GahOTsnm"
      },
      "outputs": [],
      "source": [
        "# The function to calulate the RMSE, precision@k, recall@k, and F_1 score\n",
        "def precision_recall_at_k(model: AlgoBase,\n",
        "                          testset: Dataset,\n",
        "                          k: int = 30,\n",
        "                          threshold: int = 1.5):\n",
        "    \"\"\"Computes the RMSE, precision, recall and F1 scores at k metrics for each user.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : AlgoBase\n",
        "    testset : Dataset\n",
        "    k : int = 30\n",
        "        The number of items used to compute the precision, recall, and F1 scores\n",
        "        of the model. \n",
        "    threshold : int = 1.5\n",
        "        The value to determine if an item is relevant. If true value < threshold then item\n",
        "        is not relevant.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = defaultdict(list)\n",
        "\n",
        "    # Making predictions on the test data\n",
        "    predictions=model.test(testset)\n",
        "\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key = lambda x : x[0], reverse = True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[ : k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[ : k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "    # Mean of all the predicted precisions are calculated\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "\n",
        "    # Mean of all the predicted recalls are calculated\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "\n",
        "    accuracy.rmse(predictions)\n",
        "\n",
        "    # Command to print the overall precision\n",
        "    print('Precision: ', precision)\n",
        "\n",
        "    # Command to print the overall recall\n",
        "    print('Recall: ', recall)\n",
        "\n",
        "    # Formula to compute the F-1 score\n",
        "    print('F_1 score: ', round((2 * precision * recall) / (precision + recall), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcmLRxH4IjfG"
      },
      "source": [
        "**Think About It:** In the function precision_recall_at_k above the threshold value used is 1.5. How precision and recall are affected by changing the threshold? What is the intuition behind using the threshold value of 1.5?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rGfYDiOCpe4X"
      },
      "outputs": [],
      "source": [
        "# Instantiating Reader scale with expected rating scale. Use rating scale (0, 5)\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "\n",
        "# Loading the dataset. Take only \"user_id\",\"song_id\", and \"play_count\"\n",
        "dataset = Dataset.load_from_df(df_final[[\"user_id\", \"song_id\", \"play_count\"]], reader=reader)\n",
        "\n",
        "# Splitting the data into train and test dataset. Take test_size = 0.4, random_state = 42\n",
        "trainset, testset = train_test_split(dataset, test_size=0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note about rating scale:**\n",
        "\n",
        "Since we are using a `surprise.Dataset` with a `surprise.Reader` with a `rating_scale=(0, 5)`, all `play_count` values predicted by models in this notebook will be within this range. Furthermore, the relevancy threshold value (1.5 in this notebook) and evaluation metrics (rmse, precision, recall, and f1_score) correspond to this range.\n",
        "\n",
        "As such, note that we will be interchange between the use of `play_count` or `rating` when discussing these values throughout the notebook, however they both correspond to the same concept."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuTmLjUP1aED"
      },
      "source": [
        "**Think About It:** How changing the test size would change the results and outputs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vO3FL7iape8A",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0878\n",
            "Precision:  0.396\n",
            "Recall:  0.692\n",
            "F_1 score:  0.504\n"
          ]
        }
      ],
      "source": [
        "# Build the default user-user-similarity model\n",
        "\n",
        "# The sim_options used for the base user-user model\n",
        "sim_options = {\n",
        "    \"name\": \"cosine\",\n",
        "    \"user_based\": True\n",
        "}\n",
        "\n",
        "# KNN algorithm is used to find desired similar items. Use random_state = 1\n",
        "user_user_base = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict play_count for the testset\n",
        "user_user_base.fit(trainset=trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(user_user_base, testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzcdlWmer6GA"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The base user-user model metrics are: rmse=1.0878, precision@k=0.396, recall@k=0.692, f1_score@k=0.504, where k=30 and the relevancy threshold 1.5. The recall of this model is much larger than its precision, which indicates that the model is better at identifying relevant items and recommending them to users. Notice that the f1_score is ~0.5, which means that the precision and mean of this model are essentially balanced. However, in our problem setting, maximizing recall seems to be a more appropriate metric as this means that amongst all songs that are relevant to a user the model is recommending them to the user. This minimizes the false negative rate and reduces the loss of opportunity for our business.\n",
        "\n",
        "Nevertheless, the metrics of this model are based on untuned hyperparameters and perhaps by tuning the model we are able to find more satisficatory results. Furthermore, we are in need of other models to fairly assess this model under a comparative analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_n_interacted_pairs(data: pd.DataFrame, cols: list[str], n: int = 1) -> list[tuple[int, int]]:\n",
        "    \"\"\"Choose n random rows from data and return the values in cols as a tuple.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "    cols : list[str]\n",
        "    n : int = 1\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[tuple[int, int]] \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    return list(data.sample(n, random_state=42)[cols].itertuples(index=False, name=None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Sxd23bZ9pe_x"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interacted pair : user_id=64559, song_id=211, play_count=2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Prediction(uid=64559, iid=211, r_ui=2, est=1.4733650956236064, details={'actual_k': 40, 'was_impossible': False})"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predicting play_count for a sample user with a listened song. Use any user_id and song_id\n",
        "\n",
        "# Get one (user_id, song_id, and play_count) from df_final\n",
        "inter_user_id, inter_song_id, inter_play_count = choose_n_interacted_pairs(df_final, cols=[\"user_id\", \"song_id\", \"play_count\"], n=1)[0]\n",
        "print(f\"Interacted pair : user_id={inter_user_id}, song_id={inter_song_id}, play_count={inter_play_count}\")\n",
        "\n",
        "# Predict the play_count from the above tuple\n",
        "user_user_base.predict(uid=inter_user_id, iid=inter_song_id, r_ui=inter_play_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_uninteracted_pair(data: pd.DataFrame,\n",
        "                             ground_col: str,\n",
        "                             search_col: str,\n",
        "                             ground_id: int = None) -> tuple[int, int]:\n",
        "    \"\"\"Choose a random uninteracted pair from data.\n",
        "    \n",
        "    The ground_col is used to select the initial element x and then a random\n",
        "    uninteracted element is choosen based on the values in data with\n",
        "    data[ground_col] == x.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "    ground_col : str\n",
        "        The column name for the ground item.\n",
        "    search_col : str\n",
        "        The column name for the searched item.\n",
        "    ground_id : int = None\n",
        "        The ID of the ground_col element, removing the need for the initial sample.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ground_id, search_id : tuple[int, int]\n",
        "        A tuple of the IDs of the ground and search column elements.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Set random seed for reproducible results\n",
        "    import random\n",
        "    rng = random.Random(42)\n",
        "\n",
        "    # If no ground_id is given, then sample a random value from data[ground_col]\n",
        "    if ground_id is None:\n",
        "        ground_id = data[ground_col].sample(1, random_state=42).values[0]\n",
        "\n",
        "    # Get all uids from search_col that have interacted with ground_id\n",
        "    interacted_uids = set(data[data[ground_col] == ground_id][search_col])\n",
        "\n",
        "    # Get all uids from search_col\n",
        "    all_users = set(data[search_col])\n",
        "\n",
        "    # Get uninteracted uids\n",
        "    uninteracted_uids = all_users - interacted_uids\n",
        "\n",
        "    # Choose a random uid from the set of uninteracted_uids\n",
        "    search_id = rng.choice(list(uninteracted_uids))\n",
        "\n",
        "    return ground_id, search_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PbFcBj1PpfEV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uninteracted pair : user_id=64559, song_id=9487\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Prediction(uid=64559, iid=9487, r_ui=None, est=1.6016730549116862, details={'actual_k': 40, 'was_impossible': False})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predicting play_count for a sample user with a song not-listened by the user. Predict play_count for any sample user.\n",
        "\n",
        "# Get one uninteracted user and song id pair from df_final\n",
        "uninter_user_id, uninter_song_id = choose_uninteracted_pair(df_final, ground_col=\"user_id\", search_col=\"song_id\")\n",
        "print(f\"Uninteracted pair : user_id={uninter_user_id}, song_id={uninter_song_id}\")\n",
        "\n",
        "# Predict the play_count from the above tuple\n",
        "user_user_base.predict(uid=uninter_user_id, iid=uninter_song_id, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9EVM7DysC47"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The base user-user model predicts a rating of ~1.47 for the interacted pair `user_id=64559`, `song_id=211`, with `rating=2`. This shows that the base user-user model is underestimating the true rating for this pair. Note that the predicted rating is < 1.5, which is our threshold value for relevancy/recommendation. Therefore, this pair is a false-negative, as it is a relevant example that is not recommended.\n",
        "\n",
        "The base user-user model predicts a rating of ~1.6 for the uninteracted pair `user_id=64559`, `song_id=9487`. Based on our threshold for relevancy/recommendation, this song would be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false positive. Note that in order to determine if this rating is reasonable, we can perform a comparative analysis on this pair with other models in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt1QBiylsIOm"
      },
      "source": [
        "Now, let's try to tune the model and see if we can improve the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Best score for user-user random search model: 1.0538966259051807\n",
            "Best params for user-user random search model: {'k': 100, 'min_k': 30, 'sim_options': {'name': 'msd', 'user_based': True}}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter distribution for randomized grid search\n",
        "param_distributions = {\n",
        "    \"k\": [60, 70, 80, 90, 100, 110, 120],\n",
        "    \"min_k\": [12, 15, 18, 21, 24, 27, 30],\n",
        "    \"sim_options\": {\n",
        "        \"name\": [\"msd\", \"cosine\"],\n",
        "        \"user_based\": [True]\n",
        "    }\n",
        "}\n",
        "# NOTE: there are 7x7x2x1=98 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold cross-validation to tune hyperparameters for 50 iterations\n",
        "user_user_rs = RandomizedSearchCV(KNNBasic, param_distributions=param_distributions, n_iter=50, cv=3, n_jobs=-1, random_state=1)\n",
        "\n",
        "# Fitting the data using the entire dataset\n",
        "user_user_rs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "user_user_rs_best_score = user_user_rs.best_score[\"rmse\"]\n",
        "print(f\"Best score for user-user random search model: {user_user_rs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "user_user_rs_best_params = user_user_rs.best_params[\"rmse\"]\n",
        "print(f\"Best params for user-user random search model: {user_user_rs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a random grid search for 50 iterations with 3-fold cross-validation, we found that, based on the rmse metric, the best score was ~1.053 and the best hyperparameters were `k=90, min_k=21, sim_options={\"name\": \"msd\", \"user_based\": True}`.\n",
        "\n",
        "We will now create a more compact grid around these hyperparameters to further fine-tune the model to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "T3diJPL7-tVw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Best score for user-user grid search model: 1.053518712554046\n",
            "Best params for user-user grid search model: {'k': 95, 'min_k': 21, 'sim_options': {'name': 'msd', 'user_based': True}}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter grid to tune the hyperparameters\n",
        "param_grid = {\n",
        "    \"k\": [80, 85, 90, 95, 100],\n",
        "    \"min_k\": [17, 19, 21, 23, 25],\n",
        "    \"sim_options\": {\n",
        "        \"name\": [\"msd\", \"cosine\"],\n",
        "        \"user_based\": [True]\n",
        "    }\n",
        "}\n",
        "# NOTE: there are 5x5x2x1=25 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold cross-validation to tune the hyperparameters\n",
        "user_user_gs = GridSearchCV(KNNBasic, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data with the entire dataset\n",
        "user_user_gs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "user_user_gs_best_score = user_user_gs.best_score[\"rmse\"]\n",
        "print(f\"Best score for user-user grid search model: {user_user_gs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "user_user_gs_best_params = user_user_gs.best_params[\"rmse\"]\n",
        "print(f\"Best params for user-user grid search model: {user_user_gs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a full grid search, we found that, based on the rmse metric, the best score was ~1.053 and the best hyperparameters were `k=90, min_k=19, sim_options={\"name\": \"msd\", \"user_based\": True}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PujRJA8X_JEJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0568\n",
            "Precision:  0.414\n",
            "Recall:  0.676\n",
            "F_1 score:  0.514\n"
          ]
        }
      ],
      "source": [
        "# Train the best model found in above grid search\n",
        "\n",
        "# Instantiate a KNN model using user_user_gs_best_params\n",
        "user_user_tuned = KNNBasic(**user_user_gs_best_params, verbose=False, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "user_user_tuned.fit(trainset=trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(user_user_tuned, testset=testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH5OBZ7Nse6m"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned user-user model metrics are: rmse=1.0569, precision@k=0.413, recall@k=0.668, f1_score@k=0.51, where k=30 and the relevancy threshold 1.5. Compared to the base user-user model, this tuned model performs better in terms of rmse, precision, and f1_score and slightly worse in terms of recall. However, since the f1_score of the tuned model has improved, the increase in precision outweighs the decrease in recall. We can therefore say that tuning the hyperparameters of the user-user model slightly improved our performance.\n",
        "\n",
        "Regardless, note that the metrics of this tuned model is still not phenomenal and perhaps other recommender system approaches can provide better performance. We will explore such approaches later in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FgV63lHiq1TV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.4924584637908354, details={'actual_k': 95, 'was_impossible': False})"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict the play_count for a user who has listened to the song. Take user_id 6958, song_id 1671 and r_ui = 2\n",
        "user_user_tuned.predict(uid=6958, iid=1671, r_ui=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "HXO2Ztjhq1bN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uninteracted pair : user_id=6958, song_id=8610\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=8610, r_ui=None, est=1.8461306897340055, details={'actual_k': 85, 'was_impossible': False})"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict the play_count for a song that is not listened to by the user (with user_id 6958)\n",
        "\n",
        "# Get one uninteracted song_id from df_final with user_id=6958\n",
        "uninter_user_id, uninter_song_id = choose_uninteracted_pair(df_final, ground_col=\"user_id\", search_col=\"song_id\", ground_id=6958)\n",
        "print(f\"Uninteracted pair : user_id={uninter_user_id}, song_id={uninter_song_id}\")\n",
        "\n",
        "# Predict the play_count from the above tuple\n",
        "user_user_tuned.predict(uid=uninter_user_id, iid=uninter_song_id, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdpJ--8QWuzz"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned user-user model predicts a rating of ~1.5 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the tuned user-user model is underestimating the true rating for this pair. Note that the unrounded predicted rating is < 1.5. Therefore, based on our threshold for relevancy/recommedation, this pair is a false-negative, as it is a relevant example that is not recommended.\n",
        "\n",
        "The tuned user-user model predicts a rating of ~1.85 for the uninteracted pair `user_id=6958`, `song_id=8610`. Based on our threshold for relevancy/recommendation, this song would be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ9M4pplNbWS"
      },
      "source": [
        "**Think About It:** Along with making predictions on listened and unknown songs can we get 5 nearest neighbors (most similar) to a certain song?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TbFle7cKmBJG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[31, 82, 90, 116, 125]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find five most similar items to the item with inner id 0\n",
        "user_user_tuned.get_neighbors(0, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ESobDynVNI"
      },
      "source": [
        "Below we will be implementing a function where the input parameters are:\n",
        "\n",
        "- data: A **song** dataset\n",
        "- user_id: A user-id **against which we want the recommendations**\n",
        "- top_n: The **number of songs we want to recommend**\n",
        "- algo: The algorithm we want to use **for predicting the play_count**\n",
        "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vW9V1Tk65HlY"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(data: pd.DataFrame,\n",
        "                        user_id: int,\n",
        "                        n: int,\n",
        "                        algo: AlgoBase,\n",
        "                        ground_col: str = \"user_id\",\n",
        "                        search_col: str = \"song_id\",\n",
        "                        value_col: str = \"play_count\") -> list[tuple[int, float]]:\n",
        "    \"\"\"Get top n recommendations from an algorithm for a user.\n",
        "\n",
        "    The dataframe is transformed into an user-item interaction matrix based\n",
        "    with ground_col and search_col as rows, and columns with values from\n",
        "    value_col. The matrix is then filtered to extract items that the user\n",
        "    with id=user_id has not interacted with. The algorithm is then used to\n",
        "    predict an estimate of the true value for each such item and finally the\n",
        "    top n are returned.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "    user_id : int\n",
        "    algo : AlgoBase\n",
        "    ground_col : str = \"user_id\"\n",
        "    search_col : str = \"song_id\"\n",
        "    value_col : str = \"play_count\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[tuple[int, float]]\n",
        "        A list where each element is of the form (search_id, value_est).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Creating an empty list to store the recommended ids from search column\n",
        "    recommendations = []\n",
        "\n",
        "    # Creating an user item interactions matrix\n",
        "    user_item_interactions_matrix = data.pivot(index=ground_col, columns=search_col, values=value_col)\n",
        "\n",
        "    # Extracting those item ids which the user_id has not interacted with yet\n",
        "    non_interacted_items = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
        "\n",
        "    # Looping through each of the item ids which user_id has not interacted with yet\n",
        "    for item_id in non_interacted_items:\n",
        "        # Predicting the ratings for those non-interacted item ids by this user\n",
        "        estimate = algo.predict(user_id, item_id).est\n",
        "\n",
        "        # Appending the predicted values\n",
        "        recommendations.append((item_id, estimate))\n",
        "\n",
        "    # Sorting the predicted ratings in descending order\n",
        "    recommendations.sort(key=lambda x : x[1], reverse=True)\n",
        "\n",
        "    return recommendations[:n] # Returing top n highest predicted rating items for this user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "qWbR85mI5Hrk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 recommendations for user_id=64559:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(7224, 3.2635762228834406),\n",
              " (6450, 2.7274004070266065),\n",
              " (5158, 2.6859420220610204),\n",
              " (5531, 2.4795218569155604),\n",
              " (5653, 2.426175568842111)]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make top 5 recommendations for any user_id with a similarity-based recommendation engine\n",
        "\n",
        "# Get a random user_id from df_final\n",
        "user_id = df_final[\"user_id\"].sample(1, random_state=42).values[0]\n",
        "\n",
        "# Compute the top 5 recommendations for the above user_id\n",
        "print(f\"Top 5 recommendations for user_id={user_id}:\")\n",
        "user_user_rec = get_recommendations(df_final, user_id=user_id, n=5, algo=user_user_tuned)\n",
        "user_user_rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "b5WfIX0Z6_q2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>predicted_play_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7224</td>\n",
              "      <td>3.263576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6450</td>\n",
              "      <td>2.727400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5158</td>\n",
              "      <td>2.685942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5531</td>\n",
              "      <td>2.479522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5653</td>\n",
              "      <td>2.426176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  predicted_play_count\n",
              "0     7224              3.263576\n",
              "1     6450              2.727400\n",
              "2     5158              2.685942\n",
              "3     5531              2.479522\n",
              "4     5653              2.426176"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
        "user_user_rec_df = pd.DataFrame(user_user_rec , columns=[\"song_id\", \"predicted_play_count\"])\n",
        "user_user_rec_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyhThMOttWjj"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The top five `song_id` recommendations along with their predicted play counts for `user_id=64559` are: (7224, 3.26), (6450, 2.73), (5158, 2.69), (5531, 2.47), (5653, 2.43)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghwEJY2e7INB"
      },
      "source": [
        "### Correcting the play_counts and Ranking the above songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ranking_songs(recommendations: list[tuple[int, float]], play_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Correct estimated values in recommendations based on frequency from play_data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    recommendations : list[tuple[int, float]]\n",
        "        A list of the form (song_id, est)\n",
        "    play_data : pd.DataFrame\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Sort the songs based on play counts\n",
        "    ranked_songs = play_data.loc[[iid for iid, _ in recommendations]].sort_values(\"play_frequency\", ascending=False)[[\"play_frequency\"]].reset_index()\n",
        "\n",
        "    # Merge with the recommended songs to get predicted play_count\n",
        "    ranked_songs = ranked_songs.merge(pd.DataFrame(recommendations, columns=[\"song_id\", \"predicted_play_counts\"]), on=\"song_id\", how=\"inner\")\n",
        "\n",
        "    # Rank the songs based on corrected play_counts\n",
        "    ranked_songs[\"corrected_play_counts\"] = ranked_songs[\"predicted_play_counts\"] - 1 / np.sqrt(ranked_songs[\"play_frequency\"])\n",
        "\n",
        "    # Sort the songs based on corrected play_counts\n",
        "    ranked_songs = ranked_songs.sort_values(\"corrected_play_counts\", ascending=False)\n",
        "\n",
        "    return ranked_songs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQvst41lOoMX"
      },
      "source": [
        "**Think About It:** In the above function to correct the predicted play_count a quantity 1/np.sqrt(n) is subtracted. What is the intuition behind it? Is it also possible to add this quantity instead of subtracting?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xoiAL_vH8miC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_frequency</th>\n",
              "      <th>predicted_play_counts</th>\n",
              "      <th>corrected_play_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7224</td>\n",
              "      <td>361</td>\n",
              "      <td>3.263576</td>\n",
              "      <td>3.210945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6450</td>\n",
              "      <td>263</td>\n",
              "      <td>2.727400</td>\n",
              "      <td>2.665738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5158</td>\n",
              "      <td>243</td>\n",
              "      <td>2.685942</td>\n",
              "      <td>2.621792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5531</td>\n",
              "      <td>1427</td>\n",
              "      <td>2.479522</td>\n",
              "      <td>2.453050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5653</td>\n",
              "      <td>248</td>\n",
              "      <td>2.426176</td>\n",
              "      <td>2.362676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  play_frequency  predicted_play_counts  corrected_play_counts\n",
              "1     7224             361               3.263576               3.210945\n",
              "2     6450             263               2.727400               2.665738\n",
              "4     5158             243               2.685942               2.621792\n",
              "0     5531            1427               2.479522               2.453050\n",
              "3     5653             248               2.426176               2.362676"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applying the ranking_songs function on the final_play data\n",
        "user_user_rank = ranking_songs(user_user_rec, final_play)\n",
        "user_user_rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOwwGsH8toLG"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The top five `song_id` recommendations along with their corrected play counts for `user_id=64559` are: (7224, 3.21), (6450, 2.67), (5158, 2.62), (5531, 2.44), (5653, 2.36). Notice that correcting the play counts predicted by the model had a maximum decrease of ~0.06 and that the ranking order did not change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgbzJKk7Tsnr"
      },
      "source": [
        "### Item Item Similarity-based collaborative filtering recommendation systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "W5RMcdzjTsns",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0394\n",
            "Precision:  0.307\n",
            "Recall:  0.562\n",
            "F_1 score:  0.397\n"
          ]
        }
      ],
      "source": [
        "# Apply the item-item similarity collaborative filtering model with random_state = 1 and evaluate the model performance.\n",
        "\n",
        "# The sim_options used for the base item-item model\n",
        "sim_options = {\n",
        "    \"name\": \"cosine\",\n",
        "    \"user_based\": False\n",
        "}\n",
        "\n",
        "# KNN algorithm to create a item-item similarity-based model with random_state = 1\n",
        "item_item_base = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "item_item_base.fit(trainset=trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(item_item_base, testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfdIJ6XWunx0"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The base item-item model metrics are: rmse=1.0394, precision@k=0.307, recall@k=0.562, f1_score@k=0.397, where k=30 and the relevancy threshold 1.5. This baseline model performs worse compared to the baseline user-user model in all metrics except for the rmse. This may be an indication that user-user similarity measures are more suited for this recommendation problem setting compared to item-item similarity measures. This low performance might be a result of the substantial difference between the dimension size of users and songs. In particular, since there are 3155 unique users and 563 unique songs in our dataset, item-item models operate on vectors of dimension 3155 whereas user-user models operate on vectors dimension 563. As a result, the sparsity and variability of information along the item-item vectors may be a cause of the reduced performance we see between the two baseline models.\n",
        "\n",
        "Regardless, the metrics of this model are based on untuned hyperparameters and perhaps by tuning the model we are able to find more satisficatory results. We can then more fairly access our tuned models to get a better understanding of their differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5yILOxXRTsns"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The play_count of user=6958 with song=1671 is 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.3614157231762556, details={'actual_k': 20, 'was_impossible': False})"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predicting play count for a sample user_id 6958 and song (with song_id 1671) heard by the user\n",
        "\n",
        "# Get the play_count between user_id=6958 and song_id=1671\n",
        "user_id, song_id = 6958, 1671\n",
        "r_ui = df_final[(df_final[\"user_id\"] == user_id) & (df_final[\"song_id\"] == song_id)][\"play_count\"].values[0]\n",
        "print(f\"The play_count of user={user_id} with song={song_id} is {r_ui}\")\n",
        "\n",
        "# Predict the play_count from the above tuple\n",
        "item_item_base.predict(uid=user_id, iid=song_id, r_ui=r_ui)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jSn8oK3JZsTc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uninteracted pair : user_id=39778, song_id=1671\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Prediction(uid=39778, iid=1671, r_ui=None, est=1.325921742415801, details={'actual_k': 27, 'was_impossible': False})"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict the play count for a user that has not listened to the song (with song_id 1671)\n",
        "\n",
        "# Get a random user_id that has not interacted with song_id=1671 from df_final\n",
        "uninter_song_id, uninter_user_id = choose_uninteracted_pair(df_final, ground_col=\"song_id\", search_col=\"user_id\", ground_id=1671)\n",
        "print(f\"Uninteracted pair : user_id={uninter_user_id}, song_id={uninter_song_id}\")\n",
        "\n",
        "# Predict the play_count from the above tuple\n",
        "item_item_base.predict(uid=uninter_user_id, iid=uninter_song_id, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxE9fJ8Dupby"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The base item-item model predicts a rating of ~1.36 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the base item-item model is underestimating the true rating for this pair. Note that the predicted rating is < 1.5, which is our threshold value for relevancy/recommendation. Therefore, this pair is a false-negative, as it is a relevant example that is not recommended.\n",
        "\n",
        "The base item-item model predicts a rating of ~1.33 for the uninteracted pair `user_id=39778`, `song_id=1671`. Based on our threshold for relevancy/recommendation, this song would not be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false negative. Also, note that given the metrics for this model found above as well as the predicted rating of the interacted pair above, the base item-item seems to underestimate its values. Nevertheless, in order to determine if this rating is reasonable, we need to perform a comparative analysis on this pair with other models in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Best score for item-item random search model: 1.0370040236798312\n",
            "Best params for item-item random search model: {'k': 60, 'min_k': 12, 'sim_options': {'name': 'msd', 'user_based': False}}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter distribution for randomized grid search\n",
        "param_distributions = {\n",
        "    \"k\": [60, 70, 80, 90, 100, 110, 120],\n",
        "    \"min_k\": [12, 15, 18, 21, 24, 27, 30],\n",
        "    \"sim_options\": {\n",
        "        \"name\": [\"msd\", \"cosine\"],\n",
        "        \"user_based\": [False]\n",
        "    }\n",
        "}\n",
        "# NOTE: there are 7x7x2x1=98 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold cross-validation to tune hyperparameters for 50 iterations\n",
        "item_item_rs = RandomizedSearchCV(KNNBasic, param_distributions=param_distributions, n_iter=50, cv=3, n_jobs=-1, random_state=1)\n",
        "\n",
        "# Fitting the data using the entire dataset\n",
        "item_item_rs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "item_item_rs_best_score = item_item_rs.best_score[\"rmse\"]\n",
        "print(f\"Best score for item-item random search model: {item_item_rs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "item_item_rs_best_params = item_item_rs.best_params[\"rmse\"]\n",
        "print(f\"Best params for item-item random search model: {item_item_rs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a random grid search for 50 iterations with 3-fold cross-validation, we found that, based on the rmse metric, the best score was ~1.039 and the best hyperparameters were `k=80, min_k=12, sim_options={\"name\": \"cosine\", \"user_based\": False}`.\n",
        "\n",
        "We will now create a more compact grid around these hyperparameters to further fine-tune the model to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "f5bcZ3HgTsnt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Best score for item-item grid search model: 1.0368854398034475\n",
            "Best params for item-item grid search model: {'k': 70, 'min_k': 8, 'sim_options': {'name': 'cosine', 'user_based': False}}\n"
          ]
        }
      ],
      "source": [
        "# Apply grid search for enhancing model performance\n",
        "\n",
        "# Setting up parameter grid to tune the hyperparameters\n",
        "param_grid = {\n",
        "    \"k\": [70, 75, 80, 85, 90],\n",
        "    \"min_k\": [8, 10, 12, 14, 16],\n",
        "    \"sim_options\": {\n",
        "        \"name\": [\"msd\", \"cosine\"],\n",
        "        \"user_based\": [False]\n",
        "    }\n",
        "}\n",
        "# NOTE: there are 5x5x2x1=50 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold cross-validation to tune the hyperparameters\n",
        "item_item_gs = GridSearchCV(KNNBasic, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data with the entire dataset\n",
        "item_item_gs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "item_item_gs_best_score = item_item_gs.best_score[\"rmse\"]\n",
        "print(f\"Best score for item-item grid search model: {item_item_gs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "item_item_gs_best_params = item_item_gs.best_params[\"rmse\"]\n",
        "print(f\"Best params for item-item grid search model: {item_item_gs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a full grid search, we found that, based on the rmse metric, the best score was ~1.034 and the best hyperparameters were `k=70, min_k=8, sim_options={\"name\": \"msd\", \"user_based\": False}`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXLxjLEQYvWk"
      },
      "source": [
        "**Think About It:** How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the list of hyperparameters [here](https://surprise.readthedocs.io/en/stable/knn_inspired.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dSeiM1qeTsnt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0398\n",
            "Precision:  0.321\n",
            "Recall:  0.603\n",
            "F_1 score:  0.419\n"
          ]
        }
      ],
      "source": [
        "# Apply the best model found in the grid search\n",
        "\n",
        "# Instantiate a KNN model using item_item_gs_best_params\n",
        "item_item_tuned = KNNBasic(**item_item_gs_best_params, verbose=False, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "item_item_tuned.fit(trainset=trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(item_item_tuned, testset=testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxXelRIluvfh"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned item-item model metrics are: rmse=1.0419, precision@k=0.34, recall@k=0.584, f1_score@k=0.43, where k=30 and the relevancy threshold 1.5. Compared to the base item-item model, this tuned model performs better in terms of precision, recall, f1_score and slightly worse in terms of rmse. However, the performance gains of the tuned model outweigh the slight decreaes in the model's rmse. We can therefore say that tuning the hyperparameters of the item-item model improved the overall performance.\n",
        "\n",
        "Note that compared to the tuned user-user model, the tuned item-item model performs significantly worse across all metrics, excluding rmse. It is surprising that the item-item has a better rmse score when all other metrics suffer such a decrease. It may be interesting to understand the predictions of each model to understand this discrepancy. Furthermore, based on these results, the assumptions given above for the base item-item model seem to hold more value. However, further analysis and insight is needed to make such definitive claims.\n",
        "\n",
        "As this model performs worse than the tuned user-user model, which already did not have great performance, we need to explore alternative approaches to improve upon these evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "gIBRRvdoTsnt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.3614157231762556, details={'actual_k': 20, 'was_impossible': False})"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict the play_count by a user(user_id 6958) for the song (song_id 1671)\n",
        "item_item_tuned.predict(uid=6958, iid=1671, r_ui=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "LNEgcI9PTsnu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=3232, r_ui=None, est=1.377602711737415, details={'actual_k': 20, 'was_impossible': False})"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predicting play count for a sample user_id 6958 with song_id 3232 which is not heard by the user\n",
        "item_item_tuned.predict(uid=6958, iid=3232, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf3kDSepuwcw"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned item-item model predicts a rating of ~1.33 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the tuned item-item model is underestimating the true rating for this pair. Note that the predicted rating is < 1.5, which is our threshold value for relevancy/recommedation. Therefore, this pair is a false-negative, as it is a relevant example that is not recommended.\n",
        "\n",
        "The tuned item-item model predicts a rating of ~1.47 for the uninteracted pair `user_id=6958`, `song_id=3232`. Based on our threshold for relevancy/recommendation, this song would be not be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "ZRJS4oDFTsnu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 10, 11, 24, 30]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find five most similar items to the item with inner id 0\n",
        "item_item_tuned.get_neighbors(0, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "rzoEbuZFTsnu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 recommendations for user_id=64559:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(5692, 2.230900829878001),\n",
              " (3518, 2.1215897914293467),\n",
              " (4298, 2.1158783895877646),\n",
              " (3551, 2.113824002520882),\n",
              " (9127, 2.102099886566564)]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making top 5 recommendations for any user_id  with item_item_similarity-based recommendation engine\n",
        "\n",
        "# Get a random user_id from df_final\n",
        "user_id = df_final[\"user_id\"].sample(1, random_state=42).values[0]\n",
        "\n",
        "# Compute the top 5 recommendations for the above user_id\n",
        "print(f\"Top 5 recommendations for user_id={user_id}:\")\n",
        "item_item_rec = get_recommendations(df_final, user_id=user_id, n=5, algo=item_item_tuned)\n",
        "item_item_rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "_kXVTiysTsnv"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>predicted_play_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5692</td>\n",
              "      <td>2.230901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3518</td>\n",
              "      <td>2.121590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4298</td>\n",
              "      <td>2.115878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3551</td>\n",
              "      <td>2.113824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9127</td>\n",
              "      <td>2.102100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  predicted_play_count\n",
              "0     5692              2.230901\n",
              "1     3518              2.121590\n",
              "2     4298              2.115878\n",
              "3     3551              2.113824\n",
              "4     9127              2.102100"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
        "item_item_rec_df = pd.DataFrame(item_item_rec, columns=[\"song_id\", \"predicted_play_count\"])\n",
        "item_item_rec_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "7gewfmTATsnv"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_frequency</th>\n",
              "      <th>predicted_play_counts</th>\n",
              "      <th>corrected_play_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5692</td>\n",
              "      <td>168</td>\n",
              "      <td>2.230901</td>\n",
              "      <td>2.153749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3518</td>\n",
              "      <td>272</td>\n",
              "      <td>2.121590</td>\n",
              "      <td>2.060956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4298</td>\n",
              "      <td>216</td>\n",
              "      <td>2.115878</td>\n",
              "      <td>2.047837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3551</td>\n",
              "      <td>224</td>\n",
              "      <td>2.113824</td>\n",
              "      <td>2.047009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9127</td>\n",
              "      <td>160</td>\n",
              "      <td>2.102100</td>\n",
              "      <td>2.023043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  play_frequency  predicted_play_counts  corrected_play_counts\n",
              "3     5692             168               2.230901               2.153749\n",
              "0     3518             272               2.121590               2.060956\n",
              "2     4298             216               2.115878               2.047837\n",
              "1     3551             224               2.113824               2.047009\n",
              "4     9127             160               2.102100               2.023043"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Applying the ranking_songs function on the final_play data\n",
        "item_item_rank = ranking_songs(item_item_rec, final_play)\n",
        "item_item_rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ore9XTFgv5Np"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The top five `song_id` recommendations along with their corrected play counts for `user_id=64559` are: (5823, 2.34), (3551, 2.3), (5692, 2.27), (2289, 2.19), (9127, 2.14). Notice that correcting the play counts predicted by the model had a maximum decrease of ~0.08 and that the ranking order did not change. Also, note that the predicted play counts of these top 5 recommendations from the item-item model are lower than those recommended from the user-user model. This is further evidence that the item-item model underestimates the play count and is worse model for this problem compared to the the user-user model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgJpSA9vOOL"
      },
      "source": [
        "### Model Based Collaborative Filtering - Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJynidJCw-ti"
      },
      "source": [
        "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "07-2PT5Ssjqm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0252\n",
            "Precision:  0.41\n",
            "Recall:  0.633\n",
            "F_1 score:  0.498\n"
          ]
        }
      ],
      "source": [
        "# Build baseline model using svd\n",
        "\n",
        "# Using SVD matrix factorization. Use random_state = 1\n",
        "svd_base = SVD(random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "svd_base.fit(trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(svd_base, testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:**\n",
        "\n",
        "The base svd model metrics are: rmse=1.0252, precision@k=0.41, recall@k=0.633, f1_score@k=0.498, where k=30 and the relevancy threshold 1.5. This baseline model performs better than the baseline item-item model but slightly worse than the baseline user-user model. In fact, this model even performs better than the tuned item-item model across all the metrics.\n",
        "\n",
        "Nevertheless, the metrics of this model are based on untuned hyperparameters and perhaps by tuning the model we are able to find more satisficatory results. We can then more fairly access our tuned models to get a better understanding of their differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "yWIhfdxXsjqm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.2674733972146377, details={'was_impossible': False})"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making prediction for user (with user_id 6958) to song (with song_id 1671), take r_ui = 2\n",
        "svd_base.predict(uid=6958, iid=1671, r_ui=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "APm-uMSvcAMf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=23380, iid=3232, r_ui=None, est=2.242105064658619, details={'actual_k': 17, 'was_impossible': False})"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making a prediction for the user who has not listened to the song (song_id 3232)\n",
        "\n",
        "# Get a random user_id that has not interacted with song_id=3232 from df_final\n",
        "uninter_song_id, uninter_user_id = choose_uninteracted_pair(df_final, ground_col=\"song_id\", search_col=\"user_id\", ground_id=3232)\n",
        "item_item_base.predict(uid=uninter_user_id, iid=uninter_song_id, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:**\n",
        "\n",
        "The base svd model predicts a rating of ~1.27 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the base svd model is underestimating the true rating for this pair. Note that the predicted rating is < 1.5, which is our threshold value for relevancy/recommendation. Therefore, this pair is a false-negative, as it is a relevant example that is not recommended.\n",
        "\n",
        "The base item-item model predicts a rating of ~2.24 for the uninteracted pair `user_id=23380`, `song_id=3232`. Based on our threshold for relevancy/recommendation, this song would be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23tnRUJJxWTR"
      },
      "source": [
        "#### Improving matrix factorization based recommendation system by tuning its hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score for svd random search model: 1.0021116742410778\n",
            "Best params for svd random search model: {'n_epochs': 130, 'lr_all': 0.01, 'reg_all': 0.2}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter distribution for randomized grid search\n",
        "param_distributions = {\n",
        "    \"n_epochs\": [50, 70, 90, 110, 130],\n",
        "    \"lr_all\": [0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1],\n",
        "    \"reg_all\": [0.2, 0.4, 0.6, 0.8]\n",
        "}\n",
        "# NOTE: there are 5x7x4=140 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold cross-validation to tune hyperparameters for 70 iterations\n",
        "svd_rs = RandomizedSearchCV(SVD, param_distributions=param_distributions, n_iter=70, cv=3, n_jobs=-1, random_state=1)\n",
        "\n",
        "# Fitting the data using the entire dataset\n",
        "svd_rs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "svd_rs_best_score = svd_rs.best_score[\"rmse\"]\n",
        "print(f\"Best score for svd random search model: {svd_rs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "svd_rs_best_params = svd_rs.best_params[\"rmse\"]\n",
        "print(f\"Best params for svd random search model: {svd_rs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a random grid search for 70 iterations with 3-fold cross-validation, we found that, based on the rmse metric, the best score was ~1.003 and the best hyperparameters were `n_epochs=130, lr_all=0.006, reg_all=0.2}`.\n",
        "\n",
        "We will now create a more compact grid around these hyperparameters to further fine-tune the model to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "4bM81V_hvtwv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score for svd grid search model: 0.9988966139607368\n",
            "Best params for svd grid search model: {'n_epochs': 140, 'lr_all': 0.004, 'reg_all': 0.15}\n"
          ]
        }
      ],
      "source": [
        "# Set the parameter space to tune\n",
        "param_grid = {\n",
        "    \"n_epochs\": [110, 120, 130, 140, 150],\n",
        "    \"lr_all\": [0.002, 0.004, 0.006, 0.008, 0.01],\n",
        "    \"reg_all\": [0.1, 0.15, 0.2, 0.25, 0.3]\n",
        "}\n",
        "# NOTE: there are 5x5x5=125 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold grid-search cross-validation to tune the hyperparameters\n",
        "svd_gs = GridSearchCV(SVD, param_grid=param_grid, cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data with the entire dataset\n",
        "svd_gs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "svd_gs_best_score = svd_gs.best_score[\"rmse\"]\n",
        "print(f\"Best score for svd grid search model: {svd_gs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "svd_gs_best_params = svd_gs.best_params[\"rmse\"]\n",
        "print(f\"Best params for svd grid search model: {svd_gs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a full grid search, we found that, based on the rmse metric, the best score was ~1 and the best hyperparameters were `n_epochs=140, lr_all=0.004, reg_all=0.15`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSgBRcL1xnVC"
      },
      "source": [
        "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "TA_7xe-nnhuu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0034\n",
            "Precision:  0.416\n",
            "Recall:  0.622\n",
            "F_1 score:  0.499\n"
          ]
        }
      ],
      "source": [
        "# Building the optimized SVD model using optimal hyperparameters\n",
        "\n",
        "# Instantiate a SVD model using svd_gs_best_params\n",
        "svd_tuned = SVD(**svd_gs_best_params, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "svd_tuned.fit(trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(svd_tuned, testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3t5JdBmxz8l"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned svd model metrics are: rmse=1.0034, precision@k=0.416, recall@k=0.622, f1_score@k=0.499, where k=30 and the relevancy threshold 1.5. Compared to the base svd model, this tuned model performs better in terms of rmse, precision, and f1_score and slightly worse in terms of recall. Although there are improvements to the performance of the tuned model compared to the baseline, the gains are not significant in terms of the f1_score which only increased by 0.001.\n",
        "\n",
        "Note that compared to the previous tuned user-user and item-item models, the tuned svd model performs substantially better compared to the item-item model and has a similar performance to the user-user model, where the user-user model is relatively better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "s6C1PAfboM8_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.5136521632427977, details={'was_impossible': False})"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Using svd_tuned model to recommend for userId 6958 and song_id 1671\n",
        "svd_tuned.predict(uid=6958, iid=1671, r_ui=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "k1xjn3kOoQyg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=3232, r_ui=None, est=1.4500182581573995, details={'was_impossible': False})"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Using svd_tuned model to recommend for userId 6958 and song_id 3232 with unknown baseline rating\n",
        "svd_tuned.predict(uid=6958, iid=3232, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm732Wuvy76R"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned svd model predicts a rating of ~1.51 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the tuned svd model is underestimating the true rating for this pair. Note that according to our threshold values, this pair represents a relevant example that is recommended. Interestingly, this is the first of our models that accurately recommends this song to this user.\n",
        "\n",
        "The tuned svd model predicts a rating of ~1.45 for the uninteracted pair `user_id=6958`, `song_id=3232`. Based on our threshold for relevancy/recommendation, this song would not be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false negative. Note that this predicted rating is comparably to the predicted rating from the tuned item-item model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "1LGeE2EB_n90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(7224, 2.501465148044114),\n",
              " (5653, 2.1092388295507014),\n",
              " (5531, 1.988732539786895),\n",
              " (4462, 1.986371735392652),\n",
              " (4811, 1.9779975930225806)]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting top 5 recommendations for user_id 6958 with svd_tune algorithm\n",
        "svd_rec = get_recommendations(df_final, user_id=6958, n=5, algo=svd_tuned)\n",
        "svd_rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>predicted_play_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7224</td>\n",
              "      <td>2.501465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5653</td>\n",
              "      <td>2.109239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5531</td>\n",
              "      <td>1.988733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4462</td>\n",
              "      <td>1.986372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4811</td>\n",
              "      <td>1.977998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  predicted_play_count\n",
              "0     7224              2.501465\n",
              "1     5653              2.109239\n",
              "2     5531              1.988733\n",
              "3     4462              1.986372\n",
              "4     4811              1.977998"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
        "svd_rec_df = pd.DataFrame(svd_rec, columns=[\"song_id\", \"predicted_play_count\"])\n",
        "svd_rec_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "6ngiGSJU818M"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_frequency</th>\n",
              "      <th>predicted_play_counts</th>\n",
              "      <th>corrected_play_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7224</td>\n",
              "      <td>361</td>\n",
              "      <td>2.501465</td>\n",
              "      <td>2.448834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5653</td>\n",
              "      <td>248</td>\n",
              "      <td>2.109239</td>\n",
              "      <td>2.045739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5531</td>\n",
              "      <td>1427</td>\n",
              "      <td>1.988733</td>\n",
              "      <td>1.962260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4462</td>\n",
              "      <td>336</td>\n",
              "      <td>1.986372</td>\n",
              "      <td>1.931817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4811</td>\n",
              "      <td>332</td>\n",
              "      <td>1.977998</td>\n",
              "      <td>1.923115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  play_frequency  predicted_play_counts  corrected_play_counts\n",
              "1     7224             361               2.501465               2.448834\n",
              "4     5653             248               2.109239               2.045739\n",
              "0     5531            1427               1.988733               1.962260\n",
              "2     4462             336               1.986372               1.931817\n",
              "3     4811             332               1.977998               1.923115"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ranking songs based on above recommendations\n",
        "svd_rank = ranking_songs(svd_rec, final_play)\n",
        "svd_rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SepUU1Efy_9Z"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The top five `song_id` recommendations along with their corrected play counts for `user_id=64559` are: (7224, 2.45), (5653, 2.05), (5531, 1.96), (4462, 1.93), (4811, 1.92). Notice that correcting the play counts predicted by the model had a maximum decrease of ~0.06 and that the ranking order did not change. Also, note that the predicted play counts of these top 5 recommendations from the svd model are lower than those recommended from both the user-user and item-item models. This provides some evidence that the svd model may have a tendency to underestimate play counts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57b31de5"
      },
      "source": [
        "### Cluster Based Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xv2AZCszCdN"
      },
      "source": [
        "In **clustering-based recommendation systems**, we explore the **similarities and differences** in people's tastes in songs based on how they rate different songs. We cluster similar users together and recommend songs to a user based on play_counts from other users in the same cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "0c4b20e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0487\n",
            "Precision:  0.397\n",
            "Recall:  0.582\n",
            "F_1 score:  0.472\n"
          ]
        }
      ],
      "source": [
        "# Make baseline clustering model\n",
        "cluster_base = CoClustering(random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "cluster_base.fit(trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(cluster_base, testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:**\n",
        "\n",
        "The base cluster model metrics are: rmse=1.0487, precision@k=0.397, recall@k=0.582, f1_score@k=0.472, where k=30 and the relevancy threshold 1.5. This baseline model performs better than the baseline item-item model but worse than the baseline user-user and svd models. In fact, this model performs better than the tuned item-item model in terms of the precision and f1_score metrics.\n",
        "\n",
        "Nevertheless, the metrics of this model are based on untuned hyperparameters and perhaps by tuning the model we are able to find more satisficatory results. We can then more fairly access our tuned models to get a better understanding of their differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "11dbdc0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.2941824757363074, details={'was_impossible': False})"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making prediction for user_id 6958 and song_id 1671\n",
        "cluster_base.predict(uid=6958, iid=1671, r_ui=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "dab1aaed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=3232, r_ui=None, est=1.4785259100797417, details={'was_impossible': False})"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Making prediction for user (userid 6958) for a song(song_id 3232) not heard by the user\n",
        "cluster_base.predict(uid=6958, iid=3232, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:**\n",
        "\n",
        "The tuned cluster model predicts a rating of ~1.29 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the tuned cluster model is underestimating the true rating for this pair. Note that the predicted rating is < 1.5, which is our threshold value for relevancy/recommedation. Therefore, this pair is a false-negative, as it is a relevant example that is not recommended.\n",
        "\n",
        "The tuned cluster model predicts a rating of ~1.48 for the uninteracted pair `user_id=6958`, `song_id=3232`. Based on our threshold for relevancy/recommendation, this song would be not be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2fd66f5"
      },
      "source": [
        "#### Improving clustering-based recommendation system by tuning its hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score for cluster random search model: 1.0285711852739385\n",
            "Best params for cluster random search model: {'n_cltr_u': 8, 'n_cltr_i': 1, 'n_epochs': 40}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter distribution for randomized grid search\n",
        "param_distributions = {\n",
        "    'n_cltr_u': [1, 2, 4, 6, 8, 10, 12],\n",
        "    'n_cltr_i': [1, 2, 4, 6, 8, 10, 12],\n",
        "    'n_epochs': [30, 40, 50, 60, 70, 80]\n",
        "}\n",
        "# NOTE: there are 7x7x6=294 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold cross-validation to tune hyperparameters for 150 iterations\n",
        "cluster_rs = RandomizedSearchCV(CoClustering, param_distributions=param_distributions, n_iter=150, cv=3, n_jobs=-1, random_state=1)\n",
        "\n",
        "# Fitting the data using the entire dataset\n",
        "cluster_rs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "cluster_rs_best_score = cluster_rs.best_score[\"rmse\"]\n",
        "print(f\"Best score for cluster random search model: {cluster_rs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "cluster_rs_best_params = cluster_rs.best_params[\"rmse\"]\n",
        "print(f\"Best params for cluster random search model: {cluster_rs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a random grid search for 150 iterations with 3-fold cross-validation, we found that, based on the rmse metric, the best score was ~1.029 and the best hyperparameters were `n_cltr_u=1, n_cltr_i=12, n_epochs=70`.\n",
        "\n",
        "We will now create a more compact grid around these hyperparameters to further fine-tune the model to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "efe7d8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score for cluster grid search model: 1.0300720204500828\n",
            "Best params for cluster grid search model: {'n_cltr_u': 1, 'n_cltr_i': 10, 'n_epochs': 50}\n"
          ]
        }
      ],
      "source": [
        "# Set the parameter space to tune\n",
        "param_grid = {\n",
        "    'n_cltr_u': [1, 2, 3, 4, 5],\n",
        "    'n_cltr_i': [10, 11, 12, 13, 14],\n",
        "    'n_epochs': [50, 60, 70, 80, 90]\n",
        "}\n",
        "# NOTE: there are 5x5x5=125 hyperparameter combinations.\n",
        "\n",
        "# Performing 3-fold grid-search cross-validation to tune the hyperparameters\n",
        "cluster_gs = GridSearchCV(CoClustering, param_grid, cv = 3, n_jobs = -1)\n",
        "\n",
        "# Fitting the data with the entire dataset\n",
        "cluster_gs.fit(dataset)\n",
        "\n",
        "# Best RMSE score\n",
        "cluster_gs_best_score = cluster_gs.best_score[\"rmse\"]\n",
        "print(f\"Best score for cluster grid search model: {cluster_gs_best_score}\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "cluster_gs_best_params = cluster_gs.best_params[\"rmse\"]\n",
        "print(f\"Best params for cluster grid search model: {cluster_gs_best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:** After performing a full grid search, we found that, based on the rmse metric, the best score was ~1.03 and the best hyperparameters were `n_cltr_u=1, n_cltr_i=10, n_epochs=50`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS6aMVJLyj21"
      },
      "source": [
        "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/co_clustering.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "5a7a8a30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0315\n",
            "Precision:  0.395\n",
            "Recall:  0.587\n",
            "F_1 score:  0.472\n"
          ]
        }
      ],
      "source": [
        "# Building the optimized CoClustering model using optimal hyperparameters\n",
        "\n",
        "# Instantiate a CoClustering model using cluster_gs_best_params\n",
        "cluster_tuned = CoClustering(**cluster_gs_best_params, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "cluster_tuned.fit(trainset)\n",
        "\n",
        "# Compute RMSE, precision@k, recall@k, and F1-Score with k=30\n",
        "precision_recall_at_k(cluster_tuned, testset, k=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Jvce1gznKa"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned cluster model metrics are: rmse=1.0315, precision@k=0.395, recall@k=0.587, f1_score@k=0.472, where k=30 and the relevancy threshold 1.5. Compared to the base cluster model, this tuned model performs better in terms of rmse and recall but worse in terms of precision. However, the changes between the precision and recall are balanced as the f1_score is unchanged.\n",
        "\n",
        "Note that compared to the previous tuned user-user, item-item, svd models, the tuned cluster model performs substantially better compared to the item-item model but worse compared to the user-user and svd models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "6ba5b26b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=1671, r_ui=2, est=1.1257867112267959, details={'was_impossible': False})"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Using cluster_tuned model to recommend for userId 6958 and song_id 1671\n",
        "cluster_tuned.predict(uid=6958, iid=1671, r_ui=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ec582940"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(uid=6958, iid=3232, r_ui=None, est=1.3101301455702306, details={'was_impossible': False})"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use cluster_tuned to recommend for userId 6958 and song_id 3232 with unknown baseline rating\n",
        "cluster_tuned.predict(uid=6958, iid=3232, r_ui=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjGUSMqrzoDH"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The tuned cluster model predicts a rating of ~1.13 for the interacted pair `user_id=6958`, `song_id=1671`, with `rating=2`. This shows that the tuned cluster model is extremely underestimating the true rating for this pair. Note that according to our threshold values, this pair represents a relevant example that is recommended. Interestingly, this is the first of our models that accurately recommends this song to this user.\n",
        "\n",
        "The tuned cluster model predicts a rating of ~1.31 for the uninteracted pair `user_id=6958`, `song_id=3232`. Based on our threshold for relevancy/recommendation, this song would not be recommended to the user. However, since we do not have a ground truth for this pair of users in our dataset, we are unable to determine if this rating is reasonable or not and if this example is a false negative. Note that this predicted rating is smaller compared to the predicted rating from the tuned item-item and svd models.\n",
        "\n",
        "Note that the above two examples give evidence that the cluster model severely underestimates ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9e28ba"
      },
      "source": [
        "#### Implementing the recommendation algorithm based on optimized CoClustering model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "e0f36e15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(7224, 2.9264015553199014),\n",
              " (6450, 2.1666642364793214),\n",
              " (8324, 2.1431027285428135),\n",
              " (5653, 2.1187811719631924),\n",
              " (9942, 2.046643632083717)]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting top 5 recommendations for user_id 6958 using \"Co-clustering based optimized\" algorithm\n",
        "cluster_rec = get_recommendations(df_final, user_id=6958, n=5, algo=cluster_tuned)\n",
        "cluster_rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>predicted_play_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7224</td>\n",
              "      <td>2.926402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6450</td>\n",
              "      <td>2.166664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8324</td>\n",
              "      <td>2.143103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5653</td>\n",
              "      <td>2.118781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9942</td>\n",
              "      <td>2.046644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  predicted_play_count\n",
              "0     7224              2.926402\n",
              "1     6450              2.166664\n",
              "2     8324              2.143103\n",
              "3     5653              2.118781\n",
              "4     9942              2.046644"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n",
        "cluster_rec_df = pd.DataFrame(cluster_rec, columns=[\"song_id\", \"predicted_play_count\"])\n",
        "cluster_rec_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1696941"
      },
      "source": [
        "### Correcting the play_count and Ranking the above songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "c186f13b",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_frequency</th>\n",
              "      <th>predicted_play_counts</th>\n",
              "      <th>corrected_play_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7224</td>\n",
              "      <td>361</td>\n",
              "      <td>2.926402</td>\n",
              "      <td>2.873770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6450</td>\n",
              "      <td>263</td>\n",
              "      <td>2.166664</td>\n",
              "      <td>2.105002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8324</td>\n",
              "      <td>252</td>\n",
              "      <td>2.143103</td>\n",
              "      <td>2.080109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5653</td>\n",
              "      <td>248</td>\n",
              "      <td>2.118781</td>\n",
              "      <td>2.055281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9942</td>\n",
              "      <td>373</td>\n",
              "      <td>2.046644</td>\n",
              "      <td>1.994866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   song_id  play_frequency  predicted_play_counts  corrected_play_counts\n",
              "1     7224             361               2.926402               2.873770\n",
              "2     6450             263               2.166664               2.105002\n",
              "3     8324             252               2.143103               2.080109\n",
              "4     5653             248               2.118781               2.055281\n",
              "0     9942             373               2.046644               1.994866"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ranking songs based on the above recommendations\n",
        "cluster_rank = ranking_songs(cluster_rec, final_play)\n",
        "cluster_rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uJ_nZjBzvKH"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The top five `song_id` recommendations along with their corrected play counts for `user_id=64559` are: (7224, 2.87), (6450, 2.11), (8324, 2.08), (5653, 2.06), (9942, 1.99). Notice that correcting the play counts predicted by the model had a maximum decrease of ~0.06 and that the ranking order did not change. Note that the recommendations of the cluster model intersect the recommendations from the svd model. Namely song ids 7224 and 5653 are recommended by both models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U56oSNsR-F2"
      },
      "source": [
        "### Content Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aTEqaOjhoEg"
      },
      "source": [
        "**Think About It:** So far we have only used the play_count of songs to find recommendations but we have other information/features on songs as well. Can we take those song features into account?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "UX826CsjR-F3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_count</th>\n",
              "      <th>title</th>\n",
              "      <th>release</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>year</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>6958</td>\n",
              "      <td>447</td>\n",
              "      <td>1</td>\n",
              "      <td>Daisy And Prudence</td>\n",
              "      <td>Distillation</td>\n",
              "      <td>Erin McKeown</td>\n",
              "      <td>2000</td>\n",
              "      <td>Daisy And Prudence; Distillation; Erin McKeown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>6958</td>\n",
              "      <td>512</td>\n",
              "      <td>1</td>\n",
              "      <td>The Ballad of Michael Valentine</td>\n",
              "      <td>Sawdust</td>\n",
              "      <td>The Killers</td>\n",
              "      <td>2004</td>\n",
              "      <td>The Ballad of Michael Valentine; Sawdust; The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>6958</td>\n",
              "      <td>549</td>\n",
              "      <td>1</td>\n",
              "      <td>I Stand Corrected (Album)</td>\n",
              "      <td>Vampire Weekend</td>\n",
              "      <td>Vampire Weekend</td>\n",
              "      <td>2007</td>\n",
              "      <td>I Stand Corrected (Album); Vampire Weekend; Va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>6958</td>\n",
              "      <td>703</td>\n",
              "      <td>1</td>\n",
              "      <td>They Might Follow You</td>\n",
              "      <td>Tiny Vipers</td>\n",
              "      <td>Tiny Vipers</td>\n",
              "      <td>2007</td>\n",
              "      <td>They Might Follow You; Tiny Vipers; Tiny Vipers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>6958</td>\n",
              "      <td>719</td>\n",
              "      <td>1</td>\n",
              "      <td>Monkey Man</td>\n",
              "      <td>You Know I'm No Good</td>\n",
              "      <td>Amy Winehouse</td>\n",
              "      <td>2007</td>\n",
              "      <td>Monkey Man; You Know I'm No Good; Amy Winehouse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  song_id  play_count                            title  \\\n",
              "200     6958      447           1               Daisy And Prudence   \n",
              "202     6958      512           1  The Ballad of Michael Valentine   \n",
              "203     6958      549           1        I Stand Corrected (Album)   \n",
              "204     6958      703           1            They Might Follow You   \n",
              "205     6958      719           1                       Monkey Man   \n",
              "\n",
              "                  release      artist_name  year  \\\n",
              "200          Distillation     Erin McKeown  2000   \n",
              "202               Sawdust      The Killers  2004   \n",
              "203       Vampire Weekend  Vampire Weekend  2007   \n",
              "204           Tiny Vipers      Tiny Vipers  2007   \n",
              "205  You Know I'm No Good    Amy Winehouse  2007   \n",
              "\n",
              "                                                  text  \n",
              "200     Daisy And Prudence; Distillation; Erin McKeown  \n",
              "202  The Ballad of Michael Valentine; Sawdust; The ...  \n",
              "203  I Stand Corrected (Album); Vampire Weekend; Va...  \n",
              "204    They Might Follow You; Tiny Vipers; Tiny Vipers  \n",
              "205    Monkey Man; You Know I'm No Good; Amy Winehouse  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate the \"title\", \"release\", \"artist_name\" columns to create a different column named \"text\"\n",
        "df_final[\"text\"] = df_final[\"title\"] + \"; \" + df_final[\"release\"] + \"; \" + df_final[\"artist_name\"]\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "WdXw4U-wR-F4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Daisy And Prudence</th>\n",
              "      <td>6958</td>\n",
              "      <td>447</td>\n",
              "      <td>1</td>\n",
              "      <td>Daisy And Prudence; Distillation; Erin McKeown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Ballad of Michael Valentine</th>\n",
              "      <td>6958</td>\n",
              "      <td>512</td>\n",
              "      <td>1</td>\n",
              "      <td>The Ballad of Michael Valentine; Sawdust; The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I Stand Corrected (Album)</th>\n",
              "      <td>6958</td>\n",
              "      <td>549</td>\n",
              "      <td>1</td>\n",
              "      <td>I Stand Corrected (Album); Vampire Weekend; Va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>They Might Follow You</th>\n",
              "      <td>6958</td>\n",
              "      <td>703</td>\n",
              "      <td>1</td>\n",
              "      <td>They Might Follow You; Tiny Vipers; Tiny Vipers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Monkey Man</th>\n",
              "      <td>6958</td>\n",
              "      <td>719</td>\n",
              "      <td>1</td>\n",
              "      <td>Monkey Man; You Know I'm No Good; Amy Winehouse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 user_id  song_id  play_count  \\\n",
              "title                                                           \n",
              "Daisy And Prudence                  6958      447           1   \n",
              "The Ballad of Michael Valentine     6958      512           1   \n",
              "I Stand Corrected (Album)           6958      549           1   \n",
              "They Might Follow You               6958      703           1   \n",
              "Monkey Man                          6958      719           1   \n",
              "\n",
              "                                                                              text  \n",
              "title                                                                               \n",
              "Daisy And Prudence                  Daisy And Prudence; Distillation; Erin McKeown  \n",
              "The Ballad of Michael Valentine  The Ballad of Michael Valentine; Sawdust; The ...  \n",
              "I Stand Corrected (Album)        I Stand Corrected (Album); Vampire Weekend; Va...  \n",
              "They Might Follow You              They Might Follow You; Tiny Vipers; Tiny Vipers  \n",
              "Monkey Man                         Monkey Man; You Know I'm No Good; Amy Winehouse  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select the columns 'user_id', 'song_id', 'play_count', 'title', 'text' from df_small data\n",
        "df_small = df_final[[\"user_id\", \"song_id\", \"play_count\", \"title\", \"text\"]]\n",
        "\n",
        "# Drop the duplicates from the title column\n",
        "df_small.drop_duplicates(subset=[\"title\"], inplace=True)\n",
        "\n",
        "# Set the title column as the index\n",
        "df_small = df_small.set_index(\"title\")\n",
        "\n",
        "# See the first 5 records of the df_small dataset\n",
        "df_small.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "qDcYHwZTR-F5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                 Daisy And Prudence\n",
              "1    The Ballad of Michael Valentine\n",
              "2          I Stand Corrected (Album)\n",
              "3              They Might Follow You\n",
              "4                         Monkey Man\n",
              "Name: title, dtype: object"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the series of indices from the data\n",
        "df_small_indices = pd.Series(df_small.index)\n",
        "df_small_indices.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "9UINF3Nwvwfr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/tarickali/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/tarickali/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/tarickali/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary packages to work with text data\n",
        "import nltk\n",
        "\n",
        "# Download punkt library\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Download stopwords library\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Download wordnet\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# Import regular expression\n",
        "import re\n",
        "\n",
        "# Import word_tokenizer\n",
        "from nltk import word_tokenize\n",
        "\n",
        "# Import WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Import CountVectorizer and TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt2vitlnhoEg"
      },
      "source": [
        "We will create a **function to pre-process the text data:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "j5QSSeUvR-F6"
      },
      "outputs": [],
      "source": [
        "# Create a function to tokenize the text\n",
        "def tokenize(text: str) -> list[str]:\n",
        "    \"\"\"Tokenize and lemmatize the given text.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list[str]\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Remove non-alphabetical characters and convert alphabetical characters to lowercase\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text.lower())\n",
        "\n",
        "    # Extract each word from the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove english stopwords tokens\n",
        "    words = [word for word in tokens if word not in stopwords.words(\"english\")]\n",
        "\n",
        "    # Lemmatize the words\n",
        "    wnl = WordNetLemmatizer()\n",
        "    text_lems = [wnl.lemmatize(lem).strip() for lem in words]\n",
        "\n",
        "    return text_lems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "RI_onIGdR-F6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1427</th>\n",
              "      <th>1428</th>\n",
              "      <th>1429</th>\n",
              "      <th>1430</th>\n",
              "      <th>1431</th>\n",
              "      <th>1432</th>\n",
              "      <th>1433</th>\n",
              "      <th>1434</th>\n",
              "      <th>1435</th>\n",
              "      <th>1436</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>561 rows × 1437 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1     2     3     4     5     6     7     8     9     ...  1427  \\\n",
              "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "556   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "557   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "558   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "559   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "560   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "\n",
              "     1428  1429  1430  1431  1432  1433  1434  1435  1436  \n",
              "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "556   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "557   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "558   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "559   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "560   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[561 rows x 1437 columns]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tfidf vectorizer\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
        "\n",
        "# Fit_transfrom the above vectorizer on the text column and then convert the output into an array\n",
        "songs_tfidf = tfidf.fit_transform(df_small[\"text\"].values).toarray()\n",
        "\n",
        "pd.DataFrame(songs_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Beak6ODRR-F7"
      },
      "outputs": [],
      "source": [
        "# Compute the cosine similarity for the tfidf above output\n",
        "similar_songs = cosine_similarity(songs_tfidf, songs_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jjo3UHKhoEh"
      },
      "source": [
        " Finally, let's create a function to find most similar songs to recommend for a given song."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "upANOISkR-F8"
      },
      "outputs": [],
      "source": [
        "# Function that takes in song title as input and returns the top 10 recommended songs\n",
        "def recommendations(title: str, similar_songs: np.ndarray, indices: pd.Series) -> list[str]:\n",
        "    \"\"\"Returns the top 10 recommended songs for a given song title.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    title : str\n",
        "    similar_songs : np.ndarray\n",
        "    indices : pd.Series\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[str]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    song_recommendations = []\n",
        "\n",
        "    # Getting the index of the song that matches the title\n",
        "    idx = indices[indices == title].index[0]\n",
        "\n",
        "    # Creating a Series with the similarity scores in descending order\n",
        "    sim_score_series = pd.Series(similar_songs[idx]).sort_values(ascending=False)\n",
        "\n",
        "    # Getting the indexes of the 10 most similar songs\n",
        "    top_10_idxs = list(sim_score_series.iloc[1:11].index)\n",
        "\n",
        "    # Populating the list with the titles of the best 10 matching songs\n",
        "    for i in top_10_idxs:\n",
        "        song_recommendations.append(list(indices)[i])\n",
        "\n",
        "    return song_recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4EINBmkR-F8"
      },
      "source": [
        "Recommending 10 songs similar to Learn to Fly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ohEK5dkVR-F8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Everlong',\n",
              " 'The Pretender',\n",
              " 'Nothing Better (Album)',\n",
              " 'From Left To Right',\n",
              " 'Lifespan Of A Fly',\n",
              " 'Under The Gun',\n",
              " 'I Need A Dollar',\n",
              " 'Feel The Love',\n",
              " 'All The Pretty Faces',\n",
              " 'Bones']"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make the recommendation for the song with title 'Learn To Fly'\n",
        "recommendations(\"Learn To Fly\", similar_songs=similar_songs, indices=df_small_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ7iI5QJ0oem"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "The top 10 songs similar to \"Learn To Fly\" based on our content-based recommender system are: 'Everlong', 'The Pretender', 'Nothing Better (Album)', 'From Left To Right', 'Lifespan Of A Fly', 'Under The Gun', 'I Need A Dollar', 'Feel The Love', 'All The Pretty Faces', 'Bones'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensemble Approach\n",
        "\n",
        "From our previous work building and training a variety of recommendation systems, we will create an ensemble model that takes a weighted average of the predictions from the various systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 1.0117\n",
            "Precision:  0.419\n",
            "Recall:  0.655\n",
            "F_1 score:  0.511\n"
          ]
        }
      ],
      "source": [
        "from surprise import Prediction\n",
        "\n",
        "class Ensemble(AlgoBase):\n",
        "    def __init__(self, models: list[AlgoBase], weights: list[float] = None) -> None:\n",
        "        self.models = models\n",
        "\n",
        "        # If no weights are given, then use uniform weighting\n",
        "        if weights is None:\n",
        "            self.weights = [1 / len(models) for _ in models]\n",
        "        # Otherwise, normalize weights to be a probability distribution\n",
        "        else:\n",
        "            total_weight = sum(weights)\n",
        "            self.weights = [w / total_weight for w in weights]\n",
        "\n",
        "    def predict(self, uid, iid, r_ui=None, clip=True, verbose=False) -> Prediction:\n",
        "\n",
        "        # Collect the models for each individual model on the datapoint\n",
        "        predictions: list[Prediction] = []\n",
        "        for model in self.models:\n",
        "            predictions.append(model.predict(uid, iid, r_ui=r_ui, clip=clip, verbose=verbose))\n",
        "\n",
        "        # Calculate the weighted average of the predictions\n",
        "        estimate = sum([pred.est * weight for pred, weight in zip(predictions, self.weights)])\n",
        "        prediction = Prediction(uid, iid, r_ui, estimate, {})\n",
        "\n",
        "        if verbose:\n",
        "            print(prediction)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "ensemble = Ensemble([user_user_tuned, item_item_tuned, svd_tuned, cluster_tuned], [4, 1, 3, 2])\n",
        "precision_recall_at_k(ensemble, testset=testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observation:**\n",
        "\n",
        "As expected the ensemble has slightly better performance compared to the individual weak models. In particular, there is a balance between the precision and recall metrics that gives rise to a marginal increase in the f1_score metric compared to the best performing user-user model. The ensemble model has an option to adjust the weighting for each individual model, which is a hyperparameter that can be modified based on practical experimentations with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73367782"
      },
      "source": [
        "## **Conclusion and Recommendations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5BT7Ocwqf5x"
      },
      "source": [
        "**1. Comparison of various techniques and their relative performance based on chosen Metric (Measure of success)**:\n",
        "\n",
        "The performance of each model explored in this notebook is presented in the table below.\n",
        "\n",
        "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
        "\n",
        "**2. Refined insights**:\n",
        "- What are the most meaningful insights from the data relevant to the problem?\n",
        "\n",
        "**3. Proposal for the final solution design:**\n",
        "- What model do you propose to be adopted? Why is this the best solution to adopt?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, we built and analyzed the peformance of recommender systems on song data using six distinct algorithms. We began with a rank-based system using average play counts. We then used more advanced approaches with user-user and item-item similarity-based collaborative filtering, model-based collaborative filtering (matrix factorization), clustering-based, and finally a content-based approach.\n",
        "\n",
        "To analyze and compare the performance of our models we used the **precision@k**, **recall@k**, **f1_score@k** performance metrics as well as the **rmse** error metric. The performance values found after tuning the hyperparameters for each model were as follows:\n",
        "\n",
        "| | user_user | item_item | svd | cluster |\n",
        "| -------- | ------- | ------ | ----- | ----- |\n",
        "| rmse | 1.0569 | 1.0419 | 1.0034 | 1.0315 |\n",
        "| precision | 0.413 | 0.34 | 0.416 | 0.395 |\n",
        "| recall | 0.668 | 0.584 | 0.622 | 0.587 |\n",
        "| f1_score | 0.51 | 0.43 | 0.499 | 0.472 |\n",
        "\n",
        "As the above table shows, the performance metrics of each model are much lower than expected and do not seem reasonable to be applied to a production environment. In particular, the f1_scores of each model are <= 0.51, which indicates that the precision and recall of the trained models are balanced to a < 50% harmonic mean. Although the performance of each model is unideal, the user-user model performs the best relative to the other models with the highest recall and f1_score values. Interestingly, the user-user model has the highest rmse value compared to the other models. However, since our measure of success is determined by the precision, recall, and f1_scores, we can conclude that the user-user model is relatively the best.\n",
        "\n",
        "Since all models perform below an acceptable threshold, a few improvement are needed in order to use these recommendation systems to a production environment. We first note that we performed rigorous hyperparameter tuning for each of the above models. As such, we do not believe that the performance of these models are due to poor hyperparameter values. Therefore, we suspect that the given data-model combination are unable to capture the problem complexity. Furthermore, from the sample predictions of each model explored in the notebook, we can see that each model has a tendency to predict lower play counts. Hence, composing these models as weak learners into an ensemble method may not necessarily improve our results to a satisfactory level. Nevertheless, we should see reasonable gains using an ensemble learning approach given that each model has different predictions for each user-song pair. This is one dimension of improvement that we suggest to consider for future work on this problem.\n",
        "\n",
        "Moreover, beyond using an ensemble learning approach with the base latent-models, a potentially fruitful extension would be to combine the content-based model with these base models. In this way, the content-based model can extract non-latent features that can be used to reduce the amount of latent features the base models need to discover. As a result, not only can the performance of these models improve but we can better utilize the data and information we have for the problem. In turn, these models may be better capable of capturing the problem's complexity and providing a satisfactory solution. Before this approach can be manifested, we need to resolve discrepancies in the dataset that were discovered during the data exploration phase of this notebook. Namely, the existence of the \"year 0\" value for song releases should be addressed. Furthermore, utilizing a larger fraction of the given dataset may prove to be useful when using this combined approach.\n",
        "\n",
        "In conclusion, the current models trained on the given dataset do not perform up to par, where the best model we currently have for this problem is the user-user model. In order to utilize these recommendation systems in production to improve upon or compete with companies such as Spotify, more nuanced and novel approaches are needed. We have suggested a few one-step improvements to do such, however, to create more impactful differences in our performance more informative data features and advanced algorithmic techniques are required.\n",
        "\n",
        "**Update:** We implemented an ensemble model as we previously suggested. As expected, there was not an overwhelming performance improvement by combining these weaker models. However, the ensemble model was designed to be modular and allow stakeholders and developers to add/remove weak models as they see fit as well as tune the prediction weightings of each model. Finally, although performance is still not at an acceptable state, this system is far better than a random model. Therefore, we still recommend this model to be deployed as an initial recommendation system to gather more data and user feedback."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
